<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 2 Beyond Least Squares: Using Likelihoods to Fit and Compare Models | Beyond Multiple Linear Regression</title>
  <meta name="description" content="An applied textbook on generalized linear models and multilevel models for advanced undergraduates, featuring many real, unique data sets. It is intended to be accessible to undergraduate students who have successfully completed a regression course. Even though there is no mathematical prerequisite, we still introduce fairly sophisticated topics such as likelihood theory, zero-inflated Poisson, and parametric bootstrapping in an intuitive and applied manner. We believe strongly in case studies featuring real data and real research questions; thus, most of the data in the textbook arises from collaborative research conducted by the authors and their students, or from student projects. Our goal is that, after working through this material, students will develop an expanded toolkit and a greater appreciation for the wider world of data and statistical modeling." />
  <meta name="generator" content="bookdown 0.19 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 2 Beyond Least Squares: Using Likelihoods to Fit and Compare Models | Beyond Multiple Linear Regression" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="data/cover.png" />
  <meta property="og:description" content="An applied textbook on generalized linear models and multilevel models for advanced undergraduates, featuring many real, unique data sets. It is intended to be accessible to undergraduate students who have successfully completed a regression course. Even though there is no mathematical prerequisite, we still introduce fairly sophisticated topics such as likelihood theory, zero-inflated Poisson, and parametric bootstrapping in an intuitive and applied manner. We believe strongly in case studies featuring real data and real research questions; thus, most of the data in the textbook arises from collaborative research conducted by the authors and their students, or from student projects. Our goal is that, after working through this material, students will develop an expanded toolkit and a greater appreciation for the wider world of data and statistical modeling." />
  <meta name="github-repo" content="proback/BeyondMLR" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 2 Beyond Least Squares: Using Likelihoods to Fit and Compare Models | Beyond Multiple Linear Regression" />
  
  <meta name="twitter:description" content="An applied textbook on generalized linear models and multilevel models for advanced undergraduates, featuring many real, unique data sets. It is intended to be accessible to undergraduate students who have successfully completed a regression course. Even though there is no mathematical prerequisite, we still introduce fairly sophisticated topics such as likelihood theory, zero-inflated Poisson, and parametric bootstrapping in an intuitive and applied manner. We believe strongly in case studies featuring real data and real research questions; thus, most of the data in the textbook arises from collaborative research conducted by the authors and their students, or from student projects. Our goal is that, after working through this material, students will develop an expanded toolkit and a greater appreciation for the wider world of data and statistical modeling." />
  <meta name="twitter:image" content="data/cover.png" />

<meta name="author" content="Paul Roback and Julie Legler" />


<meta name="date" content="2020-07-24" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="ch-MLRreview.html"/>
<link rel="next" href="ch-distthry.html"/>
<script src="libs/jquery/jquery.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block/empty-anchor.js"></script>
<script src="libs/kePrint/kePrint.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css\style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Broadening Your Statistical Horizons</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html"><i class="fa fa-check"></i><b>1</b> Review of Multiple Linear Regression</a><ul>
<li class="chapter" data-level="1.1" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#learning-objectives"><i class="fa fa-check"></i><b>1.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="1.2" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#introduction-to-beyond-multiple-linear-regression"><i class="fa fa-check"></i><b>1.2</b> Introduction to Beyond Multiple Linear Regression</a></li>
<li class="chapter" data-level="1.3" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#assumptions-for-linear-least-squares-regression-llsr"><i class="fa fa-check"></i><b>1.3</b> Assumptions for Linear Least Squares Regression (LLSR)</a><ul>
<li class="chapter" data-level="1.3.1" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#cases-that-do-not-violate-assumptions-for-inference-in-llsr"><i class="fa fa-check"></i><b>1.3.1</b> Cases that do not violate assumptions for inference in LLSR</a></li>
<li class="chapter" data-level="1.3.2" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#cases-where-assumptions-for-inference-in-llsr-are-violated"><i class="fa fa-check"></i><b>1.3.2</b> Cases where assumptions for inference in LLSR are violated</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#review-of-multiple-linear-regression"><i class="fa fa-check"></i><b>1.4</b> Review of Multiple Linear Regression</a><ul>
<li class="chapter" data-level="1.4.1" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#cs:derby"><i class="fa fa-check"></i><b>1.4.1</b> Case Study: Kentucky Derby</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#explorech1"><i class="fa fa-check"></i><b>1.5</b> Initial Exploratory Analyses</a><ul>
<li class="chapter" data-level="1.5.1" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#data-organization"><i class="fa fa-check"></i><b>1.5.1</b> Data Organization</a></li>
<li class="chapter" data-level="1.5.2" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#univariate-summaries"><i class="fa fa-check"></i><b>1.5.2</b> Univariate Summaries</a></li>
<li class="chapter" data-level="1.5.3" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#bivariate-summaries"><i class="fa fa-check"></i><b>1.5.3</b> Bivariate Summaries</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#multreg"><i class="fa fa-check"></i><b>1.6</b> Multiple linear regression modeling</a><ul>
<li class="chapter" data-level="1.6.1" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#SLRcontinuous"><i class="fa fa-check"></i><b>1.6.1</b> Simple linear regression with a continuous predictor</a></li>
<li class="chapter" data-level="1.6.2" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#linear-regression-with-a-binary-predictor"><i class="fa fa-check"></i><b>1.6.2</b> Linear regression with a binary predictor</a></li>
<li class="chapter" data-level="1.6.3" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#multiple-linear-regression-with-two-predictors"><i class="fa fa-check"></i><b>1.6.3</b> Multiple linear regression with two predictors</a></li>
<li class="chapter" data-level="1.6.4" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#multreg-inference"><i class="fa fa-check"></i><b>1.6.4</b> Inference in multiple linear regression: normal theory</a></li>
<li class="chapter" data-level="1.6.5" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#multreg-boot"><i class="fa fa-check"></i><b>1.6.5</b> Inference in multiple linear regression: bootstrapping</a></li>
<li class="chapter" data-level="1.6.6" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#multiple-linear-regression-with-an-interaction-term"><i class="fa fa-check"></i><b>1.6.6</b> Multiple linear regression with an interaction term</a></li>
<li class="chapter" data-level="1.6.7" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#multreg_build"><i class="fa fa-check"></i><b>1.6.7</b> Building a multiple linear regression model</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#preview-of-remaining-chapters"><i class="fa fa-check"></i><b>1.7</b> Preview of remaining chapters</a><ul>
<li class="chapter" data-level="1.7.1" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#soccer"><i class="fa fa-check"></i><b>1.7.1</b> Soccer</a></li>
<li class="chapter" data-level="1.7.2" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#elephant-mating"><i class="fa fa-check"></i><b>1.7.2</b> Elephant Mating</a></li>
<li class="chapter" data-level="1.7.3" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#parenting-and-gang-activity"><i class="fa fa-check"></i><b>1.7.3</b> Parenting and Gang Activity</a></li>
<li class="chapter" data-level="1.7.4" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#crime"><i class="fa fa-check"></i><b>1.7.4</b> Crime</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#exercises"><i class="fa fa-check"></i><b>1.8</b> Exercises</a><ul>
<li class="chapter" data-level="1.8.1" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#conceptual-exercises"><i class="fa fa-check"></i><b>1.8.1</b> Conceptual Exercises</a></li>
<li class="chapter" data-level="1.8.2" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#guided-exercises"><i class="fa fa-check"></i><b>1.8.2</b> Guided Exercises</a></li>
<li class="chapter" data-level="1.8.3" data-path="ch-MLRreview.html"><a href="ch-MLRreview.html#open-ended-exercises"><i class="fa fa-check"></i><b>1.8.3</b> Open-ended Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html"><i class="fa fa-check"></i><b>2</b> Beyond Least Squares: Using Likelihoods to Fit and Compare Models</a><ul>
<li class="chapter" data-level="2.1" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#learning-objectives-1"><i class="fa fa-check"></i><b>2.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="2.2" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#case-study-does-sex-run-in-families"><i class="fa fa-check"></i><b>2.2</b> Case Study: Does sex run in families?</a><ul>
<li class="chapter" data-level="2.2.1" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#research-questions"><i class="fa fa-check"></i><b>2.2.1</b> Research Questions</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#model-0-sex-unconditional-model-equal-probabilities-independence"><i class="fa fa-check"></i><b>2.3</b> Model 0: Sex Unconditional Model (Equal probabilities, Independence)</a></li>
<li class="chapter" data-level="2.4" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#sex_unconditional_model"><i class="fa fa-check"></i><b>2.4</b> Model 1: Sex Unconditional Model (Any Probability, Independence)</a><ul>
<li class="chapter" data-level="2.4.1" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#what-is-a-likelihood"><i class="fa fa-check"></i><b>2.4.1</b> What is a likelihood?</a></li>
<li class="chapter" data-level="2.4.2" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#findMLE.sec"><i class="fa fa-check"></i><b>2.4.2</b> Finding MLEs</a></li>
<li class="chapter" data-level="2.4.3" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#summary"><i class="fa fa-check"></i><b>2.4.3</b> Summary</a></li>
<li class="chapter" data-level="2.4.4" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#is-a-likelihood-a-probability-function-optional"><i class="fa fa-check"></i><b>2.4.4</b> Is a likelihood a probability function? (Optional)</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#sex_conditional.sec"><i class="fa fa-check"></i><b>2.5</b> Model 2: Sex Conditional Model (Sex Bias)</a><ul>
<li class="chapter" data-level="2.5.1" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#model-specification"><i class="fa fa-check"></i><b>2.5.1</b> Model Specification</a></li>
<li class="chapter" data-level="2.5.2" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#application-to-hypothetical-data"><i class="fa fa-check"></i><b>2.5.2</b> Application to Hypothetical Data</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#case-study-analysis-of-the-nlsy-data"><i class="fa fa-check"></i><b>2.6</b> Case Study: Analysis of the NLSY data</a><ul>
<li class="chapter" data-level="2.6.1" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#model-building-plan"><i class="fa fa-check"></i><b>2.6.1</b> Model Building Plan</a></li>
<li class="chapter" data-level="2.6.2" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#EDA.sec"><i class="fa fa-check"></i><b>2.6.2</b> Family Composition of Boys and Girls, NLSY: Exploratory Data Analysis</a></li>
<li class="chapter" data-level="2.6.3" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#likelihood-for-the-sex-unconditional-model-the-nlsy-data"><i class="fa fa-check"></i><b>2.6.3</b> Likelihood for the Sex Unconditional Model: the NLSY data</a></li>
<li class="chapter" data-level="2.6.4" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#sex-cond-lik"><i class="fa fa-check"></i><b>2.6.4</b> Likelihood for the Sex Conditional Model</a></li>
<li class="chapter" data-level="2.6.5" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#sec-lrtest"><i class="fa fa-check"></i><b>2.6.5</b> Comparing the Sex Unconditional to the Sex Conditional Model</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#model-3-stopping-rule-model-waiting-for-a-boy"><i class="fa fa-check"></i><b>2.7</b> Model 3: Stopping Rule Model (Waiting for a boy)</a><ul>
<li class="chapter" data-level="2.7.1" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#non-nested-models"><i class="fa fa-check"></i><b>2.7.1</b> Non-nested Models</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#summary-of-model-building"><i class="fa fa-check"></i><b>2.8</b> Summary of Model Building</a></li>
<li class="chapter" data-level="2.9" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#likelihood-based-methods"><i class="fa fa-check"></i><b>2.9</b> Likelihood-based Methods</a></li>
<li class="chapter" data-level="2.10" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#likelihoods-and-this-course"><i class="fa fa-check"></i><b>2.10</b> Likelihoods and this Course</a></li>
<li class="chapter" data-level="2.11" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#exercises-1"><i class="fa fa-check"></i><b>2.11</b> Exercises</a><ul>
<li class="chapter" data-level="2.11.1" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#conceptual-exercises-1"><i class="fa fa-check"></i><b>2.11.1</b> Conceptual Exercises</a></li>
<li class="chapter" data-level="2.11.2" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#guided-exercises-1"><i class="fa fa-check"></i><b>2.11.2</b> Guided Exercises</a></li>
<li class="chapter" data-level="2.11.3" data-path="ch-beyondmost.html"><a href="ch-beyondmost.html#open-ended-exercise"><i class="fa fa-check"></i><b>2.11.3</b> Open-ended Exercise</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="ch-distthry.html"><a href="ch-distthry.html"><i class="fa fa-check"></i><b>3</b> Distribution Theory</a><ul>
<li class="chapter" data-level="3.1" data-path="ch-distthry.html"><a href="ch-distthry.html#learning-objectives-2"><i class="fa fa-check"></i><b>3.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="3.2" data-path="ch-distthry.html"><a href="ch-distthry.html#introduction"><i class="fa fa-check"></i><b>3.2</b> Introduction</a></li>
<li class="chapter" data-level="3.3" data-path="ch-distthry.html"><a href="ch-distthry.html#discrete-random-variables"><i class="fa fa-check"></i><b>3.3</b> Discrete Random Variables</a><ul>
<li class="chapter" data-level="3.3.1" data-path="ch-distthry.html"><a href="ch-distthry.html#sec-binary"><i class="fa fa-check"></i><b>3.3.1</b> Binary Random Variable</a></li>
<li class="chapter" data-level="3.3.2" data-path="ch-distthry.html"><a href="ch-distthry.html#sec-binomial"><i class="fa fa-check"></i><b>3.3.2</b> Binomial Random Variable</a></li>
<li class="chapter" data-level="3.3.3" data-path="ch-distthry.html"><a href="ch-distthry.html#geometric-random-variable"><i class="fa fa-check"></i><b>3.3.3</b> Geometric Random Variable</a></li>
<li class="chapter" data-level="3.3.4" data-path="ch-distthry.html"><a href="ch-distthry.html#negative-binomial-random-variable"><i class="fa fa-check"></i><b>3.3.4</b> Negative Binomial Random Variable</a></li>
<li class="chapter" data-level="3.3.5" data-path="ch-distthry.html"><a href="ch-distthry.html#hypergeometric-random-variable"><i class="fa fa-check"></i><b>3.3.5</b> Hypergeometric Random Variable</a></li>
<li class="chapter" data-level="3.3.6" data-path="ch-distthry.html"><a href="ch-distthry.html#poisson-random-variable"><i class="fa fa-check"></i><b>3.3.6</b> Poisson Random Variable</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="ch-distthry.html"><a href="ch-distthry.html#continuous-random-variables"><i class="fa fa-check"></i><b>3.4</b> Continuous Random Variables</a><ul>
<li class="chapter" data-level="3.4.1" data-path="ch-distthry.html"><a href="ch-distthry.html#exponential-random-variable"><i class="fa fa-check"></i><b>3.4.1</b> Exponential Random Variable</a></li>
<li class="chapter" data-level="3.4.2" data-path="ch-distthry.html"><a href="ch-distthry.html#gamma-random-variable"><i class="fa fa-check"></i><b>3.4.2</b> Gamma Random Variable</a></li>
<li class="chapter" data-level="3.4.3" data-path="ch-distthry.html"><a href="ch-distthry.html#normal-gaussian-random-variable"><i class="fa fa-check"></i><b>3.4.3</b> Normal (Gaussian) Random Variable</a></li>
<li class="chapter" data-level="3.4.4" data-path="ch-distthry.html"><a href="ch-distthry.html#beta-random-variable"><i class="fa fa-check"></i><b>3.4.4</b> Beta Random Variable</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="ch-distthry.html"><a href="ch-distthry.html#distributions-used-in-testing"><i class="fa fa-check"></i><b>3.5</b> Distributions used in Testing</a><ul>
<li class="chapter" data-level="3.5.1" data-path="ch-distthry.html"><a href="ch-distthry.html#chi2-distribution"><i class="fa fa-check"></i><b>3.5.1</b> <span class="math inline">\(\chi^2\)</span> Distribution</a></li>
<li class="chapter" data-level="3.5.2" data-path="ch-distthry.html"><a href="ch-distthry.html#students-tdistribution"><i class="fa fa-check"></i><b>3.5.2</b> Student’s <span class="math inline">\(t\)</span>–Distribution</a></li>
<li class="chapter" data-level="3.5.3" data-path="ch-distthry.html"><a href="ch-distthry.html#fdistribution"><i class="fa fa-check"></i><b>3.5.3</b> <span class="math inline">\(F\)</span>–Distribution</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="ch-distthry.html"><a href="ch-distthry.html#additional-resources"><i class="fa fa-check"></i><b>3.6</b> Additional Resources</a></li>
<li class="chapter" data-level="3.7" data-path="ch-distthry.html"><a href="ch-distthry.html#exercises-2"><i class="fa fa-check"></i><b>3.7</b> Exercises</a><ul>
<li class="chapter" data-level="3.7.1" data-path="ch-distthry.html"><a href="ch-distthry.html#conceptual-exercises-2"><i class="fa fa-check"></i><b>3.7.1</b> Conceptual Exercises</a></li>
<li class="chapter" data-level="3.7.2" data-path="ch-distthry.html"><a href="ch-distthry.html#guided-exercises-2"><i class="fa fa-check"></i><b>3.7.2</b> Guided Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html"><i class="fa fa-check"></i><b>4</b> Poisson Regression</a><ul>
<li class="chapter" data-level="4.1" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#learning-objectives-3"><i class="fa fa-check"></i><b>4.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="4.2" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#introduction-to-poisson-regression"><i class="fa fa-check"></i><b>4.2</b> Introduction to Poisson Regression</a><ul>
<li class="chapter" data-level="4.2.1" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#poisson-regression-assumptions"><i class="fa fa-check"></i><b>4.2.1</b> Poisson Regression Assumptions</a></li>
<li class="chapter" data-level="4.2.2" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#a-graphical-look-at-poisson-regression"><i class="fa fa-check"></i><b>4.2.2</b> A Graphical Look at Poisson Regression</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#case-studies-overview"><i class="fa fa-check"></i><b>4.3</b> Case Studies Overview</a></li>
<li class="chapter" data-level="4.4" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#cs-philippines"><i class="fa fa-check"></i><b>4.4</b> Case Study: Household Size in the Philippines</a><ul>
<li class="chapter" data-level="4.4.1" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#organizedata4"><i class="fa fa-check"></i><b>4.4.1</b> Data Organization</a></li>
<li class="chapter" data-level="4.4.2" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#exploreHH"><i class="fa fa-check"></i><b>4.4.2</b> Exploratory Data Analyses</a></li>
<li class="chapter" data-level="4.4.3" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#sec-PoisInference"><i class="fa fa-check"></i><b>4.4.3</b> Estimation and Inference</a></li>
<li class="chapter" data-level="4.4.4" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#sec-Devtocompare"><i class="fa fa-check"></i><b>4.4.4</b> Using Deviances to Compare Models</a></li>
<li class="chapter" data-level="4.4.5" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#likelihood.sec"><i class="fa fa-check"></i><b>4.4.5</b> Using Likelihoods to fit Poisson Regression Models (Optional)</a></li>
<li class="chapter" data-level="4.4.6" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#second-order-model"><i class="fa fa-check"></i><b>4.4.6</b> Second Order Model</a></li>
<li class="chapter" data-level="4.4.7" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#adding-a-covariate"><i class="fa fa-check"></i><b>4.4.7</b> Adding a covariate</a></li>
<li class="chapter" data-level="4.4.8" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#sec-PoisResid"><i class="fa fa-check"></i><b>4.4.8</b> Residuals for Poisson Models (Optional)</a></li>
<li class="chapter" data-level="4.4.9" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#sec-PoisGOF"><i class="fa fa-check"></i><b>4.4.9</b> Goodness-of-fit</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#linear-least-squares-regression-vs.-poisson-regression"><i class="fa fa-check"></i><b>4.5</b> Linear Least Squares Regression  vs. Poisson Regression </a></li>
<li class="chapter" data-level="4.6" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#case-study-campus-crime"><i class="fa fa-check"></i><b>4.6</b> Case Study: Campus Crime</a><ul>
<li class="chapter" data-level="4.6.1" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#data-organization-1"><i class="fa fa-check"></i><b>4.6.1</b> Data Organization</a></li>
<li class="chapter" data-level="4.6.2" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#exploratory-data-analysis"><i class="fa fa-check"></i><b>4.6.2</b> Exploratory Data Analysis</a></li>
<li class="chapter" data-level="4.6.3" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#accounting-for-enrollment"><i class="fa fa-check"></i><b>4.6.3</b> Accounting for Enrollment</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#modeling-assumptions"><i class="fa fa-check"></i><b>4.7</b> Modeling Assumptions</a></li>
<li class="chapter" data-level="4.8" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#initial-models"><i class="fa fa-check"></i><b>4.8</b> Initial Models</a><ul>
<li class="chapter" data-level="4.8.1" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#tukeys-honestly-significant-differences"><i class="fa fa-check"></i><b>4.8.1</b> Tukey’s Honestly Significant Differences</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#sec-overdispPois"><i class="fa fa-check"></i><b>4.9</b> Overdispersion</a><ul>
<li class="chapter" data-level="4.9.1" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#dispersion-parameter-adjustment"><i class="fa fa-check"></i><b>4.9.1</b> Dispersion parameter adjustment</a></li>
<li class="chapter" data-level="4.9.2" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#no-dispersion-vs.-overdispersion"><i class="fa fa-check"></i><b>4.9.2</b> No dispersion vs. overdispersion</a></li>
<li class="chapter" data-level="4.9.3" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#negative-binomial-modeling"><i class="fa fa-check"></i><b>4.9.3</b> Negative binomial modeling</a></li>
</ul></li>
<li class="chapter" data-level="4.10" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#cs:drinking"><i class="fa fa-check"></i><b>4.10</b> Case Study: Weekend drinking</a><ul>
<li class="chapter" data-level="4.10.1" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#research-question"><i class="fa fa-check"></i><b>4.10.1</b> Research Question</a></li>
<li class="chapter" data-level="4.10.2" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#data-organization-2"><i class="fa fa-check"></i><b>4.10.2</b> Data Organization</a></li>
<li class="chapter" data-level="4.10.3" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#exploratory-data-analysis-1"><i class="fa fa-check"></i><b>4.10.3</b> Exploratory Data Analysis</a></li>
<li class="chapter" data-level="4.10.4" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#modeling"><i class="fa fa-check"></i><b>4.10.4</b> Modeling</a></li>
<li class="chapter" data-level="4.10.5" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#fitting-a-zip-model"><i class="fa fa-check"></i><b>4.10.5</b> Fitting a ZIP Model</a></li>
<li class="chapter" data-level="4.10.6" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#comparing-zip-to-ordinary-poisson-with-the-vuong-test-optional"><i class="fa fa-check"></i><b>4.10.6</b> Comparing ZIP to ordinary Poisson with the Vuong Test (Optional)</a></li>
<li class="chapter" data-level="4.10.7" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#residual-plot"><i class="fa fa-check"></i><b>4.10.7</b> Residual Plot</a></li>
<li class="chapter" data-level="4.10.8" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#limitations"><i class="fa fa-check"></i><b>4.10.8</b> Limitations</a></li>
</ul></li>
<li class="chapter" data-level="4.11" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#exercises-3"><i class="fa fa-check"></i><b>4.11</b> Exercises</a><ul>
<li class="chapter" data-level="4.11.1" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#exer:concept"><i class="fa fa-check"></i><b>4.11.1</b> Conceptual Exercises</a></li>
<li class="chapter" data-level="4.11.2" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#guided-exercises-3"><i class="fa fa-check"></i><b>4.11.2</b> Guided Exercises</a></li>
<li class="chapter" data-level="4.11.3" data-path="ch-poissonreg.html"><a href="ch-poissonreg.html#open-ended-exercises-1"><i class="fa fa-check"></i><b>4.11.3</b> Open-ended Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="ch-glms.html"><a href="ch-glms.html"><i class="fa fa-check"></i><b>5</b> Generalized Linear Models (GLMs): A Unifying Theory</a><ul>
<li class="chapter" data-level="5.1" data-path="ch-glms.html"><a href="ch-glms.html#learning-objectives-4"><i class="fa fa-check"></i><b>5.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="5.2" data-path="ch-glms.html"><a href="ch-glms.html#one-parameter-exponential-families"><i class="fa fa-check"></i><b>5.2</b> One parameter exponential families</a><ul>
<li class="chapter" data-level="5.2.1" data-path="ch-glms.html"><a href="ch-glms.html#one-parameter-exponential-family-possion"><i class="fa fa-check"></i><b>5.2.1</b> One Parameter Exponential Family: Possion</a></li>
<li class="chapter" data-level="5.2.2" data-path="ch-glms.html"><a href="ch-glms.html#one-parameter-exponential-family-normal"><i class="fa fa-check"></i><b>5.2.2</b> One parameter exponential family: Normal</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="ch-glms.html"><a href="ch-glms.html#generalized-linear-modeling"><i class="fa fa-check"></i><b>5.3</b> Generalized Linear Modeling</a></li>
<li class="chapter" data-level="5.4" data-path="ch-glms.html"><a href="ch-glms.html#exercises-4"><i class="fa fa-check"></i><b>5.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="ch-logreg.html"><a href="ch-logreg.html"><i class="fa fa-check"></i><b>6</b> Logistic Regression</a><ul>
<li class="chapter" data-level="6.1" data-path="ch-logreg.html"><a href="ch-logreg.html#learning-objectives-5"><i class="fa fa-check"></i><b>6.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="6.2" data-path="ch-logreg.html"><a href="ch-logreg.html#introduction-to-logistic-regression"><i class="fa fa-check"></i><b>6.2</b> Introduction to Logistic Regression</a><ul>
<li class="chapter" data-level="6.2.1" data-path="ch-logreg.html"><a href="ch-logreg.html#logistic-regression-assumptions"><i class="fa fa-check"></i><b>6.2.1</b> Logistic Regression Assumptions</a></li>
<li class="chapter" data-level="6.2.2" data-path="ch-logreg.html"><a href="ch-logreg.html#a-graphical-look-at-logistic-regression"><i class="fa fa-check"></i><b>6.2.2</b> A Graphical Look at Logistic Regression</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="ch-logreg.html"><a href="ch-logreg.html#case-studies-overview-1"><i class="fa fa-check"></i><b>6.3</b> Case Studies Overview</a></li>
<li class="chapter" data-level="6.4" data-path="ch-logreg.html"><a href="ch-logreg.html#case-study-soccer-goalkeepers"><i class="fa fa-check"></i><b>6.4</b> Case Study: Soccer Goalkeepers</a><ul>
<li class="chapter" data-level="6.4.1" data-path="ch-logreg.html"><a href="ch-logreg.html#modeling-odds"><i class="fa fa-check"></i><b>6.4.1</b> Modeling Odds</a></li>
<li class="chapter" data-level="6.4.2" data-path="ch-logreg.html"><a href="ch-logreg.html#logistic-regression-models-for-binomial-responses"><i class="fa fa-check"></i><b>6.4.2</b> Logistic Regression Models for Binomial Responses</a></li>
<li class="chapter" data-level="6.4.3" data-path="ch-logreg.html"><a href="ch-logreg.html#theoretical-rationale-for-logistic-regression-models-optional"><i class="fa fa-check"></i><b>6.4.3</b> Theoretical rationale for logistic regression models (Optional)</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="ch-logreg.html"><a href="ch-logreg.html#case-study-reconstructing-alabama"><i class="fa fa-check"></i><b>6.5</b> Case Study: Reconstructing Alabama</a><ul>
<li class="chapter" data-level="6.5.1" data-path="ch-logreg.html"><a href="ch-logreg.html#data-organization-3"><i class="fa fa-check"></i><b>6.5.1</b> Data Organization</a></li>
<li class="chapter" data-level="6.5.2" data-path="ch-logreg.html"><a href="ch-logreg.html#exploratory-analyses"><i class="fa fa-check"></i><b>6.5.2</b> Exploratory Analyses</a></li>
<li class="chapter" data-level="6.5.3" data-path="ch-logreg.html"><a href="ch-logreg.html#initial-models-1"><i class="fa fa-check"></i><b>6.5.3</b> Initial Models</a></li>
<li class="chapter" data-level="6.5.4" data-path="ch-logreg.html"><a href="ch-logreg.html#sec-logisticInf"><i class="fa fa-check"></i><b>6.5.4</b> Tests for significance of model coefficients</a></li>
<li class="chapter" data-level="6.5.5" data-path="ch-logreg.html"><a href="ch-logreg.html#confidence-intervals-for-model-coefficients"><i class="fa fa-check"></i><b>6.5.5</b> Confidence intervals for model coefficients</a></li>
<li class="chapter" data-level="6.5.6" data-path="ch-logreg.html"><a href="ch-logreg.html#testing-for-goodness-of-fit"><i class="fa fa-check"></i><b>6.5.6</b> Testing for goodness of fit</a></li>
<li class="chapter" data-level="6.5.7" data-path="ch-logreg.html"><a href="ch-logreg.html#residuals-for-binomial-regression"><i class="fa fa-check"></i><b>6.5.7</b> Residuals for Binomial Regression</a></li>
<li class="chapter" data-level="6.5.8" data-path="ch-logreg.html"><a href="ch-logreg.html#sec-logOverdispersion"><i class="fa fa-check"></i><b>6.5.8</b> Overdispersion</a></li>
<li class="chapter" data-level="6.5.9" data-path="ch-logreg.html"><a href="ch-logreg.html#summary-1"><i class="fa fa-check"></i><b>6.5.9</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="ch-logreg.html"><a href="ch-logreg.html#linear-least-squares-regression-vs.-binomial-logistic-regression"><i class="fa fa-check"></i><b>6.6</b> Linear Least Squares Regression  vs. Binomial Logistic Regression </a></li>
<li class="chapter" data-level="6.7" data-path="ch-logreg.html"><a href="ch-logreg.html#case-study-trying-to-lose-weight"><i class="fa fa-check"></i><b>6.7</b> Case Study: Trying to Lose Weight</a><ul>
<li class="chapter" data-level="6.7.1" data-path="ch-logreg.html"><a href="ch-logreg.html#data-organization-4"><i class="fa fa-check"></i><b>6.7.1</b> Data Organization</a></li>
<li class="chapter" data-level="6.7.2" data-path="ch-logreg.html"><a href="ch-logreg.html#exploratory-data-analysis-2"><i class="fa fa-check"></i><b>6.7.2</b> Exploratory Data Analysis</a></li>
<li class="chapter" data-level="6.7.3" data-path="ch-logreg.html"><a href="ch-logreg.html#initial-models-2"><i class="fa fa-check"></i><b>6.7.3</b> Initial Models</a></li>
<li class="chapter" data-level="6.7.4" data-path="ch-logreg.html"><a href="ch-logreg.html#drop-in-deviance-tests"><i class="fa fa-check"></i><b>6.7.4</b> Drop-in-deviance Tests</a></li>
<li class="chapter" data-level="6.7.5" data-path="ch-logreg.html"><a href="ch-logreg.html#model-discussion-and-summary"><i class="fa fa-check"></i><b>6.7.5</b> Model Discussion and Summary</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="ch-logreg.html"><a href="ch-logreg.html#exercises-5"><i class="fa fa-check"></i><b>6.8</b> Exercises</a><ul>
<li class="chapter" data-level="6.8.1" data-path="ch-logreg.html"><a href="ch-logreg.html#conceptual-exercises-3"><i class="fa fa-check"></i><b>6.8.1</b> Conceptual Exercises</a></li>
<li class="chapter" data-level="6.8.2" data-path="ch-logreg.html"><a href="ch-logreg.html#guided-exercises-4"><i class="fa fa-check"></i><b>6.8.2</b> Guided Exercises</a></li>
<li class="chapter" data-level="6.8.3" data-path="ch-logreg.html"><a href="ch-logreg.html#open-ended-exercises-2"><i class="fa fa-check"></i><b>6.8.3</b> Open-ended Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="ch-corrdata.html"><a href="ch-corrdata.html"><i class="fa fa-check"></i><b>7</b> Correlated Data</a><ul>
<li class="chapter" data-level="7.1" data-path="ch-corrdata.html"><a href="ch-corrdata.html#learning-objectives-6"><i class="fa fa-check"></i><b>7.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="7.2" data-path="ch-corrdata.html"><a href="ch-corrdata.html#introduction-1"><i class="fa fa-check"></i><b>7.2</b> Introduction</a></li>
<li class="chapter" data-level="7.3" data-path="ch-corrdata.html"><a href="ch-corrdata.html#recognizing-correlation"><i class="fa fa-check"></i><b>7.3</b> Recognizing correlation</a></li>
<li class="chapter" data-level="7.4" data-path="ch-corrdata.html"><a href="ch-corrdata.html#case-study-dams-and-pups"><i class="fa fa-check"></i><b>7.4</b> Case Study: Dams and pups</a></li>
<li class="chapter" data-level="7.5" data-path="ch-corrdata.html"><a href="ch-corrdata.html#sources-of-variability"><i class="fa fa-check"></i><b>7.5</b> Sources of Variability</a></li>
<li class="chapter" data-level="7.6" data-path="ch-corrdata.html"><a href="ch-corrdata.html#scenario-1-no-covariates"><i class="fa fa-check"></i><b>7.6</b> Scenario 1: No covariates</a></li>
<li class="chapter" data-level="7.7" data-path="ch-corrdata.html"><a href="ch-corrdata.html#scenario-2-dose-effect"><i class="fa fa-check"></i><b>7.7</b> Scenario 2: Dose effect</a></li>
<li class="chapter" data-level="7.8" data-path="ch-corrdata.html"><a href="ch-corrdata.html#case-study-tree-growth"><i class="fa fa-check"></i><b>7.8</b> Case Study: Tree Growth</a><ul>
<li class="chapter" data-level="7.8.1" data-path="ch-corrdata.html"><a href="ch-corrdata.html#format-of-the-data-set"><i class="fa fa-check"></i><b>7.8.1</b> Format of the data set</a></li>
<li class="chapter" data-level="7.8.2" data-path="ch-corrdata.html"><a href="ch-corrdata.html#sources-of-variability-1"><i class="fa fa-check"></i><b>7.8.2</b> Sources of variability</a></li>
<li class="chapter" data-level="7.8.3" data-path="ch-corrdata.html"><a href="ch-corrdata.html#analysis-preview-accounting-for-correlation-within-transect"><i class="fa fa-check"></i><b>7.8.3</b> Analysis preview: accounting for correlation within transect</a></li>
</ul></li>
<li class="chapter" data-level="7.9" data-path="ch-corrdata.html"><a href="ch-corrdata.html#summary-2"><i class="fa fa-check"></i><b>7.9</b> Summary</a></li>
<li class="chapter" data-level="7.10" data-path="ch-corrdata.html"><a href="ch-corrdata.html#exercises-6"><i class="fa fa-check"></i><b>7.10</b> Exercises</a><ul>
<li class="chapter" data-level="7.10.1" data-path="ch-corrdata.html"><a href="ch-corrdata.html#conceptual-exercises-4"><i class="fa fa-check"></i><b>7.10.1</b> Conceptual Exercises</a></li>
<li class="chapter" data-level="7.10.2" data-path="ch-corrdata.html"><a href="ch-corrdata.html#guided-exercises-5"><i class="fa fa-check"></i><b>7.10.2</b> Guided Exercises</a></li>
<li class="chapter" data-level="7.10.3" data-path="ch-corrdata.html"><a href="ch-corrdata.html#note-on-correlated-binary-outcomes"><i class="fa fa-check"></i><b>7.10.3</b> Note on Correlated Binary Outcomes</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html"><i class="fa fa-check"></i><b>8</b> Introduction to Multilevel Models</a><ul>
<li class="chapter" data-level="8.1" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#learning-objectives-7"><i class="fa fa-check"></i><b>8.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="8.2" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#cs:music"><i class="fa fa-check"></i><b>8.2</b> Case Study: Music Performance Anxiety</a></li>
<li class="chapter" data-level="8.3" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#explore"><i class="fa fa-check"></i><b>8.3</b> Initial Exploratory Analyses</a><ul>
<li class="chapter" data-level="8.3.1" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#organizedata1"><i class="fa fa-check"></i><b>8.3.1</b> Data Organization</a></li>
<li class="chapter" data-level="8.3.2" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#explore1"><i class="fa fa-check"></i><b>8.3.2</b> Exploratory Analyses: Univariate Summaries</a></li>
<li class="chapter" data-level="8.3.3" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#explore2"><i class="fa fa-check"></i><b>8.3.3</b> Exploratory Analyses: Bivariate Summaries</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#twolevelmodeling"><i class="fa fa-check"></i><b>8.4</b> Two level modeling: preliminary considerations</a><ul>
<li class="chapter" data-level="8.4.1" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#multregr"><i class="fa fa-check"></i><b>8.4.1</b> Ignoring the two level structure (not recommended)</a></li>
<li class="chapter" data-level="8.4.2" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#twostage"><i class="fa fa-check"></i><b>8.4.2</b> A two-stage modeling approach (better but imperfect)</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#twolevelmodelingunified"><i class="fa fa-check"></i><b>8.5</b> Two level modeling: a unified approach</a><ul>
<li class="chapter" data-level="8.5.1" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#ourframework"><i class="fa fa-check"></i><b>8.5.1</b> Our framework</a></li>
<li class="chapter" data-level="8.5.2" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#random-vs.-fixed-effects"><i class="fa fa-check"></i><b>8.5.2</b> Random vs. fixed effects</a></li>
<li class="chapter" data-level="8.5.3" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#MVN"><i class="fa fa-check"></i><b>8.5.3</b> Distribution of errors: the multivariate normal distribution</a></li>
<li class="chapter" data-level="8.5.4" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#multileveltechnical"><i class="fa fa-check"></i><b>8.5.4</b> Technical issues when estimating and testing parameters (Optional)</a></li>
<li class="chapter" data-level="8.5.5" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#initialmodel"><i class="fa fa-check"></i><b>8.5.5</b> An initial model with parameter interpretations</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#sec:buildmodel"><i class="fa fa-check"></i><b>8.6</b> Building a multilevel model</a><ul>
<li class="chapter" data-level="8.6.1" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#buildstrategy"><i class="fa fa-check"></i><b>8.6.1</b> Model building strategy</a></li>
<li class="chapter" data-level="8.6.2" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#modela8"><i class="fa fa-check"></i><b>8.6.2</b> An initial model: unconditional means or random intercepts</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#modelb"><i class="fa fa-check"></i><b>8.7</b> Binary covariates at Level One and Level Two</a><ul>
<li class="chapter" data-level="8.7.1" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#randomslopeandint"><i class="fa fa-check"></i><b>8.7.1</b> Random slopes and intercepts model</a></li>
<li class="chapter" data-level="8.7.2" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#pseudoR2"><i class="fa fa-check"></i><b>8.7.2</b> Pseudo <span class="math inline">\(R^2\)</span> values</a></li>
<li class="chapter" data-level="8.7.3" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#modelc"><i class="fa fa-check"></i><b>8.7.3</b> Adding a covariate at Level Two</a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#sec:modeld"><i class="fa fa-check"></i><b>8.8</b> Additional covariates: model comparison and interpretability</a><ul>
<li class="chapter" data-level="8.8.1" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#interp:modeld"><i class="fa fa-check"></i><b>8.8.1</b> Interpretation of parameter estimates</a></li>
<li class="chapter" data-level="8.8.2" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#compare:modeld"><i class="fa fa-check"></i><b>8.8.2</b> Model comparisons</a></li>
</ul></li>
<li class="chapter" data-level="8.9" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#sec:modele"><i class="fa fa-check"></i><b>8.9</b> Center covariates</a></li>
<li class="chapter" data-level="8.10" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#modelf"><i class="fa fa-check"></i><b>8.10</b> A potential final model for music performance anxiety</a></li>
<li class="chapter" data-level="8.11" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#multinecessary"><i class="fa fa-check"></i><b>8.11</b> Modeling the multilevel structure: is it really necessary?</a></li>
<li class="chapter" data-level="8.12" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#notesr8"><i class="fa fa-check"></i><b>8.12</b> Notes on Using R (Optional)</a></li>
<li class="chapter" data-level="8.13" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#exercises-7"><i class="fa fa-check"></i><b>8.13</b> Exercises</a><ul>
<li class="chapter" data-level="8.13.1" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#conceptual-exercises-5"><i class="fa fa-check"></i><b>8.13.1</b> Conceptual Exercises</a></li>
<li class="chapter" data-level="8.13.2" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#guided-exercise"><i class="fa fa-check"></i><b>8.13.2</b> Guided Exercise</a></li>
<li class="chapter" data-level="8.13.3" data-path="ch-multilevelintro.html"><a href="ch-multilevelintro.html#open-ended-exercises-3"><i class="fa fa-check"></i><b>8.13.3</b> Open-ended Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="ch-lon.html"><a href="ch-lon.html"><i class="fa fa-check"></i><b>9</b> Two Level Longitudinal Data</a><ul>
<li class="chapter" data-level="9.1" data-path="ch-lon.html"><a href="ch-lon.html#learning-objectives-8"><i class="fa fa-check"></i><b>9.1</b> Learning objectives</a></li>
<li class="chapter" data-level="9.2" data-path="ch-lon.html"><a href="ch-lon.html#cs:charter"><i class="fa fa-check"></i><b>9.2</b> Case study: Charter schools</a></li>
<li class="chapter" data-level="9.3" data-path="ch-lon.html"><a href="ch-lon.html#exploratoryanalysis"><i class="fa fa-check"></i><b>9.3</b> Initial Exploratory Analyses</a><ul>
<li class="chapter" data-level="9.3.1" data-path="ch-lon.html"><a href="ch-lon.html#data"><i class="fa fa-check"></i><b>9.3.1</b> Data organization</a></li>
<li class="chapter" data-level="9.3.2" data-path="ch-lon.html"><a href="ch-lon.html#missing"><i class="fa fa-check"></i><b>9.3.2</b> Missing data</a></li>
<li class="chapter" data-level="9.3.3" data-path="ch-lon.html"><a href="ch-lon.html#generalanalyses"><i class="fa fa-check"></i><b>9.3.3</b> Exploratory analyses for general multilevel models</a></li>
<li class="chapter" data-level="9.3.4" data-path="ch-lon.html"><a href="ch-lon.html#longitudinalanalyses"><i class="fa fa-check"></i><b>9.3.4</b> Exploratory analyses for longitudinal data</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="ch-lon.html"><a href="ch-lon.html#twostage9"><i class="fa fa-check"></i><b>9.4</b> Preliminary two-stage modeling</a><ul>
<li class="chapter" data-level="9.4.1" data-path="ch-lon.html"><a href="ch-lon.html#lineartwostage"><i class="fa fa-check"></i><b>9.4.1</b> Linear trends within schools</a></li>
<li class="chapter" data-level="9.4.2" data-path="ch-lon.html"><a href="ch-lon.html#lineartwostageL2effects"><i class="fa fa-check"></i><b>9.4.2</b> Effects of level two covariates on linear time trends</a></li>
<li class="chapter" data-level="9.4.3" data-path="ch-lon.html"><a href="ch-lon.html#lineartwostageerror2"><i class="fa fa-check"></i><b>9.4.3</b> Error structure within schools</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="ch-lon.html"><a href="ch-lon.html#lineartwostageerror"><i class="fa fa-check"></i><b>9.5</b> Initial models</a><ul>
<li class="chapter" data-level="9.5.1" data-path="ch-lon.html"><a href="ch-lon.html#modela"><i class="fa fa-check"></i><b>9.5.1</b> Unconditional means model</a></li>
<li class="chapter" data-level="9.5.2" data-path="ch-lon.html"><a href="ch-lon.html#modelb9"><i class="fa fa-check"></i><b>9.5.2</b> Unconditional growth model</a></li>
<li class="chapter" data-level="9.5.3" data-path="ch-lon.html"><a href="ch-lon.html#othertimetrends"><i class="fa fa-check"></i><b>9.5.3</b> Modeling other trends over time</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="ch-lon.html"><a href="ch-lon.html#finalmodel"><i class="fa fa-check"></i><b>9.6</b> Building to a final model</a><ul>
<li class="chapter" data-level="9.6.1" data-path="ch-lon.html"><a href="ch-lon.html#sec:modelc9"><i class="fa fa-check"></i><b>9.6.1</b> Uncontrolled effects of school type</a></li>
<li class="chapter" data-level="9.6.2" data-path="ch-lon.html"><a href="ch-lon.html#modeld"><i class="fa fa-check"></i><b>9.6.2</b> Add percent free and reduced lunch as a covariate</a></li>
<li class="chapter" data-level="9.6.3" data-path="ch-lon.html"><a href="ch-lon.html#modelf9"><i class="fa fa-check"></i><b>9.6.3</b> A potential final model with three Level Two covariates</a></li>
<li class="chapter" data-level="9.6.4" data-path="ch-lon.html"><a href="ch-lon.html#longitudinal-paraboot"><i class="fa fa-check"></i><b>9.6.4</b> Parametric bootstrap testing</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="ch-lon.html"><a href="ch-lon.html#errorcovariance"><i class="fa fa-check"></i><b>9.7</b> Covariance structure among observations</a><ul>
<li class="chapter" data-level="9.7.1" data-path="ch-lon.html"><a href="ch-lon.html#standarderror"><i class="fa fa-check"></i><b>9.7.1</b> Standard covariance structure</a></li>
<li class="chapter" data-level="9.7.2" data-path="ch-lon.html"><a href="ch-lon.html#alternateerror"><i class="fa fa-check"></i><b>9.7.2</b> Alternative covariance structures</a></li>
<li class="chapter" data-level="9.7.3" data-path="ch-lon.html"><a href="ch-lon.html#covariance-structure-in-non-longitudinal-multilevel-models"><i class="fa fa-check"></i><b>9.7.3</b> Covariance structure in non-longitudinal multilevel models</a></li>
<li class="chapter" data-level="9.7.4" data-path="ch-lon.html"><a href="ch-lon.html#final-thoughts-regarding-covariance-structures"><i class="fa fa-check"></i><b>9.7.4</b> Final thoughts regarding covariance structures</a></li>
<li class="chapter" data-level="9.7.5" data-path="ch-lon.html"><a href="ch-lon.html#optionalcov"><i class="fa fa-check"></i><b>9.7.5</b> Details of covariance structures (Optional)</a></li>
</ul></li>
<li class="chapter" data-level="9.8" data-path="ch-lon.html"><a href="ch-lon.html#notesr9"><i class="fa fa-check"></i><b>9.8</b> Notes on Using R (Optional)</a></li>
<li class="chapter" data-level="9.9" data-path="ch-lon.html"><a href="ch-lon.html#exercises-8"><i class="fa fa-check"></i><b>9.9</b> Exercises</a><ul>
<li class="chapter" data-level="9.9.1" data-path="ch-lon.html"><a href="ch-lon.html#conceptual-exercises-6"><i class="fa fa-check"></i><b>9.9.1</b> Conceptual Exercises</a></li>
<li class="chapter" data-level="9.9.2" data-path="ch-lon.html"><a href="ch-lon.html#guided-exercise-1"><i class="fa fa-check"></i><b>9.9.2</b> Guided Exercise</a></li>
<li class="chapter" data-level="9.9.3" data-path="ch-lon.html"><a href="ch-lon.html#open-ended-exercises-4"><i class="fa fa-check"></i><b>9.9.3</b> Open-ended Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="ch-3level.html"><a href="ch-3level.html"><i class="fa fa-check"></i><b>10</b> Multilevel Data With More Than Two Levels</a><ul>
<li class="chapter" data-level="10.1" data-path="ch-3level.html"><a href="ch-3level.html#learning-objectives-9"><i class="fa fa-check"></i><b>10.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="10.2" data-path="ch-3level.html"><a href="ch-3level.html#cs:seeds"><i class="fa fa-check"></i><b>10.2</b> Case Studies: Seed Germination</a></li>
<li class="chapter" data-level="10.3" data-path="ch-3level.html"><a href="ch-3level.html#explore3"><i class="fa fa-check"></i><b>10.3</b> Initial Exploratory Analyses</a><ul>
<li class="chapter" data-level="10.3.1" data-path="ch-3level.html"><a href="ch-3level.html#organizedata3"><i class="fa fa-check"></i><b>10.3.1</b> Data Organization</a></li>
<li class="chapter" data-level="10.3.2" data-path="ch-3level.html"><a href="ch-3level.html#explore3v2"><i class="fa fa-check"></i><b>10.3.2</b> Exploratory Analyses</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="ch-3level.html"><a href="ch-3level.html#initialmodels-3level"><i class="fa fa-check"></i><b>10.4</b> Initial models: unconditional means and unconditional growth</a></li>
<li class="chapter" data-level="10.5" data-path="ch-3level.html"><a href="ch-3level.html#sec:boundary"><i class="fa fa-check"></i><b>10.5</b> Encountering boundary constraints</a></li>
<li class="chapter" data-level="10.6" data-path="ch-3level.html"><a href="ch-3level.html#threelevel-paraboot"><i class="fa fa-check"></i><b>10.6</b> Parametric bootstrap testing</a></li>
<li class="chapter" data-level="10.7" data-path="ch-3level.html"><a href="ch-3level.html#sec:explodingvarcomps"><i class="fa fa-check"></i><b>10.7</b> Exploding variance components</a></li>
<li class="chapter" data-level="10.8" data-path="ch-3level.html"><a href="ch-3level.html#modelsDEF"><i class="fa fa-check"></i><b>10.8</b> Building to a final model</a></li>
<li class="chapter" data-level="10.9" data-path="ch-3level.html"><a href="ch-3level.html#error-3level"><i class="fa fa-check"></i><b>10.9</b> Covariance structure (Optional)</a><ul>
<li class="chapter" data-level="10.9.1" data-path="ch-3level.html"><a href="ch-3level.html#optionalerror"><i class="fa fa-check"></i><b>10.9.1</b> Details of covariance structures</a></li>
</ul></li>
<li class="chapter" data-level="10.10" data-path="ch-3level.html"><a href="ch-3level.html#usingR3"><i class="fa fa-check"></i><b>10.10</b> Notes on Using R (Optional)</a></li>
<li class="chapter" data-level="10.11" data-path="ch-3level.html"><a href="ch-3level.html#exercises-9"><i class="fa fa-check"></i><b>10.11</b> Exercises</a><ul>
<li class="chapter" data-level="10.11.1" data-path="ch-3level.html"><a href="ch-3level.html#conceptual-exercises-7"><i class="fa fa-check"></i><b>10.11.1</b> Conceptual Exercises</a></li>
<li class="chapter" data-level="10.11.2" data-path="ch-3level.html"><a href="ch-3level.html#guided-exercises-6"><i class="fa fa-check"></i><b>10.11.2</b> Guided Exercises</a></li>
<li class="chapter" data-level="10.11.3" data-path="ch-3level.html"><a href="ch-3level.html#open-ended-exercises-5"><i class="fa fa-check"></i><b>10.11.3</b> Open-ended Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="ch-GLMM.html"><a href="ch-GLMM.html"><i class="fa fa-check"></i><b>11</b> Multilevel Generalized Linear Models</a><ul>
<li class="chapter" data-level="11.1" data-path="ch-GLMM.html"><a href="ch-GLMM.html#objectives"><i class="fa fa-check"></i><b>11.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="11.2" data-path="ch-GLMM.html"><a href="ch-GLMM.html#cs:refs"><i class="fa fa-check"></i><b>11.2</b> Case Study: College Basketball Referees</a></li>
<li class="chapter" data-level="11.3" data-path="ch-GLMM.html"><a href="ch-GLMM.html#explore-glmm"><i class="fa fa-check"></i><b>11.3</b> Initial Exploratory Analyses</a><ul>
<li class="chapter" data-level="11.3.1" data-path="ch-GLMM.html"><a href="ch-GLMM.html#data-organization-5"><i class="fa fa-check"></i><b>11.3.1</b> Data organization</a></li>
<li class="chapter" data-level="11.3.2" data-path="ch-GLMM.html"><a href="ch-GLMM.html#glmm-eda"><i class="fa fa-check"></i><b>11.3.2</b> Exploratory analyses</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="ch-GLMM.html"><a href="ch-GLMM.html#twolevelmodeling-glmm"><i class="fa fa-check"></i><b>11.4</b> Two level Modeling with a Generalized Response</a><ul>
<li class="chapter" data-level="11.4.1" data-path="ch-GLMM.html"><a href="ch-GLMM.html#multregr-glmm"><i class="fa fa-check"></i><b>11.4.1</b> A GLM approach (correlation not accounted for)</a></li>
<li class="chapter" data-level="11.4.2" data-path="ch-GLMM.html"><a href="ch-GLMM.html#twostage-glmm"><i class="fa fa-check"></i><b>11.4.2</b> A two-stage modeling approach (provides the basic idea for multilevel modeling)</a></li>
<li class="chapter" data-level="11.4.3" data-path="ch-GLMM.html"><a href="ch-GLMM.html#unified-glmm"><i class="fa fa-check"></i><b>11.4.3</b> A unified multilevel approach (the framework we’ll use)</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="ch-GLMM.html"><a href="ch-GLMM.html#crossedre"><i class="fa fa-check"></i><b>11.5</b> Crossed Random Effects</a></li>
<li class="chapter" data-level="11.6" data-path="ch-GLMM.html"><a href="ch-GLMM.html#glmm-paraboot"><i class="fa fa-check"></i><b>11.6</b> Model Comparisons Using the Parametric Bootstrap</a></li>
<li class="chapter" data-level="11.7" data-path="ch-GLMM.html"><a href="ch-GLMM.html#sec:finalmodel-glmm"><i class="fa fa-check"></i><b>11.7</b> A Potential Final Model for Examining Referee Bias</a></li>
<li class="chapter" data-level="11.8" data-path="ch-GLMM.html"><a href="ch-GLMM.html#estimatedRE"><i class="fa fa-check"></i><b>11.8</b> Estimated Random Effects</a></li>
<li class="chapter" data-level="11.9" data-path="ch-GLMM.html"><a href="ch-GLMM.html#usingR-glmm"><i class="fa fa-check"></i><b>11.9</b> Notes on Using R (Optional)</a></li>
<li class="chapter" data-level="11.10" data-path="ch-GLMM.html"><a href="ch-GLMM.html#exercises-10"><i class="fa fa-check"></i><b>11.10</b> Exercises</a><ul>
<li class="chapter" data-level="11.10.1" data-path="ch-GLMM.html"><a href="ch-GLMM.html#conceptual-exercises-8"><i class="fa fa-check"></i><b>11.10.1</b> Conceptual Exercises</a></li>
<li class="chapter" data-level="11.10.2" data-path="ch-GLMM.html"><a href="ch-GLMM.html#open-ended-exercises-6"><i class="fa fa-check"></i><b>11.10.2</b> Open-ended Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Beyond Multiple Linear Regression</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ch-beyondmost" class="section level1">
<h1><span class="header-section-number">Chapter 2</span> Beyond Least Squares: Using Likelihoods to Fit and Compare Models</h1>
<div id="learning-objectives-1" class="section level2">
<h2><span class="header-section-number">2.1</span> Learning Objectives</h2>
<p>After finishing this chapter, you should be able to:</p>
<ul>
<li>Describe the concept of a likelihood, in words.</li>
<li>Know and apply the Principle of Maximum Likelihood for a simple example.</li>
<li>Identify three ways in which you can obtain or approximate an MLE .</li>
<li>Use likelihoods to compare models.</li>
<li>Construct a likelihood for a simple model.</li>
</ul>
<p>This text encourages you to broaden your statistical horizons by moving beyond independent, identically distributed, normal responses (iidN). This chapter on likelihood focuses on ways to fit models, determine estimates, and compare models for a wide range of types of responses, not just iidN data. In your earlier study of statistics, you fit simple linear models using ordinary least squares (OLS). Fitting those models assumes that the mean value of a response, Y, is linearly related to some variable, X. However, often responses are not normally distributed. For example, a study in education may involve scoring responses on a test as correct or incorrect. This binary response may be explained by the number of hours students spend studying. However we do not expect a variable which takes on only 0 or 1 to be a linear function of time spent studying (see Figure <a href="ch-beyondmost.html#fig:logistic1">2.1</a>).</p>

<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="ch-beyondmost.html#cb31-1"></a><span class="co"># Packages required for Chapter 2</span></span>
<span id="cb31-2"><a href="ch-beyondmost.html#cb31-2"></a><span class="kw">library</span>(gridExtra)  </span>
<span id="cb31-3"><a href="ch-beyondmost.html#cb31-3"></a><span class="kw">library</span>(knitr) </span>
<span id="cb31-4"><a href="ch-beyondmost.html#cb31-4"></a><span class="kw">library</span>(mosaic)</span>
<span id="cb31-5"><a href="ch-beyondmost.html#cb31-5"></a><span class="kw">library</span>(xtable)</span>
<span id="cb31-6"><a href="ch-beyondmost.html#cb31-6"></a><span class="kw">library</span>(kableExtra)</span>
<span id="cb31-7"><a href="ch-beyondmost.html#cb31-7"></a><span class="kw">library</span>(tidyverse) </span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:logistic1"></span>
<img src="bookdown-BeyondMLR_files/figure-html/logistic1-1.png" alt="An attempt to fit a linear regression model to a binary response variable." width="90%" />
<p class="caption">
Figure 2.1: An attempt to fit a linear regression model to a binary response variable.
</p>
</div>
<p>In this instance we’ll use logistic regression instead of linear least squares regression. Fitting a logistic regression requires the use of likelihood methods. Another setting where likelihood methods come into play is when data is produced from a complex structure which may imply correlation among outcomes. For example, test scores for students who have been taught by the same teacher may be correlated. We’ll see that likelihood methods are useful when modeling correlated data. Likelihood methods not only provide a great deal of flexibility in the types of models we can fit, but they also provide ways in which to compare models as well. You might find likelihood methods a bit more complicated, but conceptually the approach is straightforward. As you go through the material here, worry less about calculus and computational details and focus on the concepts. You will have software to help you with computation, but model specification and interpretation will be up to you.</p>
</div>
<div id="case-study-does-sex-run-in-families" class="section level2">
<h2><span class="header-section-number">2.2</span> Case Study: Does sex run in families?</h2>
<p>Doesn’t it seem that some families tend to have lots of boys while others have more than their share of girls? Is it really the case that each child human couples produce is equally likely to be a male or female? Or does sex run in families? It can be argued that these kinds of questions have implications for population demographics and sibling harmony. For example, a 2009 study at the University of Ulster found that growing up with sisters, as compared to brothers, can enhance the quality of life of an adult <span class="citation">(BBC News <a href="#ref-BBCNEWS1995" role="doc-biblioref">2009</a>)</span>.</p>
<p>Sibling harmony aside, why do people care about gender imbalance? Comparisons of sex ratios between countries illustrate some compelling reasons. Some think that genetic or biological influences within families, such as “sex running in families,” can affect sex ratios. Mating behavior such as waiting until the family includes a boy or both sexes affects sex ratios. Some believe that sex ratios point to the practice of sex selection in a country accomplished through abortion or infanticide. Furthermore, there is speculation that an excess of men could lead to unrest among young males unable to find marriage partners or start families.</p>
<p>In 1930, statistician R.A. Fisher posited a 50:50 equilibrium theory regarding sex ratios in terms of parental expenditure. Most often, in practice, sex ratios differ from what Fisher predicted. From 1970 to 2002, the sex ratio at birth in the US among white non-Hispanics was 105 boys to 100 girls, but only 103 boys to 100 girls among African Americans and Native Americans <span class="citation">(Mathews and Hamilton <a href="#ref-Mathews2005" role="doc-biblioref">2005</a>)</span>. A 1997 study in <em>Nature</em> reports evidence which suggests that the human sex ratio may be currently shifting in the United States toward more female babies, closer to Fisher’s prediction! <span class="citation">(Komdeur et al. <a href="#ref-Komdeur1997" role="doc-biblioref">1997</a>)</span> Sex ratio comparisons between countries are also intriguing. For example, Switzerland has a sex ratio of 106 boys to 100 girls whereas there are 112 boys to every 100 girls in China acoording to The World Factbook <span class="citation">(Central Intelligence Agency <a href="#ref-CIA2013" role="doc-biblioref">2013</a>)</span>. In the next section, we bring the notion of gender imbalance closer to home by focusing on families instead of countries or sub-populations.</p>
<p>To investigate this question and others, we look at the gender composition of 5,626 families collected by the National Longitudinal Survey of Youth <span class="citation">(Bureau of Labor Statistics <a href="#ref-NLSY1997" role="doc-biblioref">1997</a>)</span>. We fit models to explore whether there is evidence sex runs in families, a model we refer to as a Sex Conditional Model. We also consider a separate but related question about whether couples are “waiting for a boy.” <span class="citation">(Rodgers and Doughty <a href="#ref-Rodgers2001" role="doc-biblioref">2001</a>)</span>.</p>
<div id="research-questions" class="section level3">
<h3><span class="header-section-number">2.2.1</span> Research Questions</h3>
<p>We specify several models related to gender balance in families. Our models liken having babies to flipping a coin (heads=boy, tails=girl), of course, recognizing that in truth there is a little more to having babies. The baseline model (Model 0) assumes that the probability of a boy is the same as a probability of a girl. The first model (Model 1) considers the situation that the coin is loaded and the probability of heads (a boy) is different than the probability of tails (a girl). Next, we consider a model (Model 2) that conditions on the previous number of boys or girls in a family to get at the question of whether sex runs in families. This data is also used for a different set of models that relate to couples’ behavior. Specifically, we look to see if there is evidence that couples are waiting for a boy. searching for evidence of waiting for a girl, or waiting for both a boy and a girl, are left as exercises.</p>
<p>Models 0 and 1 assume that having children is like flipping a coin. The gender of each child is independent of the gender of other children and the probability of a boy is the same for each new child. Let <span class="math inline">\(p_B\)</span> be the probability a child is a boy.</p>
<ol style="list-style-type: decimal">
<li><strong>Model 0: Sex Unconditional Model (Equal probabilities)</strong> Is a child just as likely to be a boy as it is to be a girl; is <span class="math inline">\(p_B\)</span> = 0.5?</li>
<li><strong>Model 1: Sex Unconditional Model (Different probabilities)</strong> Is the coin loaded; is <span class="math inline">\(p_B \neq 0.5\)</span>?</li>
<li><strong>Model 2: Sex Conditional Model (Sex bias)</strong>: Do boys or girls run in families? That is,
is there a tendency for families with more boys than girls to be more likely to produce another boy? Is the case the same for girls?</li>
<li><strong>Model 3: Stopping Rule Model (Waiting for a boy)</strong>
Is there evidence that couples stop having children once a boy is born?</li>
</ol>
<p>Ultimately, our goal is to incorporate the family composition data represented as series of coin flips to find the “best” estimate for the probability of having a boy, <span class="math inline">\(p_B\)</span>, and evaluate the assumptions built into these models. We will be using likelihood-based methods, not ordinary least squares, to fit and compare these models.</p>
<p>While the NLSY data is of interest, we start with a smaller, hypothetical data set of 30 families with a total of 50 children in order to illustrate concepts related to likelihoods (Table <a href="ch-beyondmost.html#tab:table1chp2">2.1</a>). The data are the frequencies of possible family gender compositions for one-, two-, and three-child families. The methods we develop on this small data set will then be applied to the one-, two- and three-family NLSY data. It is straightforward to include all of the family sizes up to the four-or five-child families in the NLSY data.</p>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:table1chp2">Table 2.1: </span>The gender composition of 30 families in the hypothetical data set of n=50 children.
</caption>
<thead>
<tr>
<th style="text-align:left;">
Composition
</th>
<th style="text-align:right;">
Number of families
</th>
<th style="text-align:right;">
Number of children
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
B
</td>
<td style="text-align:right;">
6
</td>
<td style="text-align:right;">
6
</td>
</tr>
<tr>
<td style="text-align:left;">
G
</td>
<td style="text-align:right;">
7
</td>
<td style="text-align:right;">
7
</td>
</tr>
<tr>
<td style="text-align:left;">
BB
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
10
</td>
</tr>
<tr>
<td style="text-align:left;">
BG
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
8
</td>
</tr>
<tr>
<td style="text-align:left;">
GB
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
10
</td>
</tr>
<tr>
<td style="text-align:left;">
GGB
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
3
</td>
</tr>
<tr>
<td style="text-align:left;">
GBB
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
6
</td>
</tr>
<tr>
<td style="text-align:left;">
Total
</td>
<td style="text-align:right;">
30
</td>
<td style="text-align:right;">
50
</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="model-0-sex-unconditional-model-equal-probabilities-independence" class="section level2">
<h2><span class="header-section-number">2.3</span> Model 0: Sex Unconditional Model (Equal probabilities, Independence)</h2>
<p>For the Sex Unconditional models, having children is modeled using coin flips. With a coin flip model, the result of each flip is independent of results of other flips. With this version of the Sex Unconditional Model, the chance that a baby is a boy is specified to be <span class="math inline">\(p_B=0.5\)</span>. It makes no difference if the first and third children are boys, the probability that the second child is a boy is 0.5; that is, the results for each child are <strong>independent</strong>  of the others. Under this model you expect to see equal numbers of boys and girls.</p>
</div>
<div id="sex_unconditional_model" class="section level2">
<h2><span class="header-section-number">2.4</span> Model 1: Sex Unconditional Model (Any Probability, Independence)</h2>
<p>You may want your model to allow for the probability of a boy, <span class="math inline">\(p_B\)</span>, to be something different than 0.5. With this version of the Sex Unconditional model, <span class="math inline">\(p_B&gt;0.5\)</span> or <span class="math inline">\(p_B&lt;0.5\)</span> or <span class="math inline">\(p_B=0.5\)</span>, in which case you expect to see more boys than girls or fewer boys than girls or equal numbers of boys and girls, respectively. We would retain the assumption of independence; that is, the probability of a boy, <span class="math inline">\(p_B\)</span>, is the same for each child. Seeing a boy for the first child will not lead you to change the probability that the second child is a boy; this would not imply that “sex runs in families.”</p>
<div id="what-is-a-likelihood" class="section level3">
<h3><span class="header-section-number">2.4.1</span> What is a likelihood?</h3>
<p>As is often the case in statistics, our objective is to find an estimate for a model parameter using our data; here, the parameter to estimate is the probability of a boy, <span class="math inline">\(p_B\)</span>, and the data is the gender composition for each family. One way in which to interpret probability is to imagine repeatedly producing children. The probability of a boy will be the overall proportion of boys as the number of children increases.
With likelihood methods, conceptually we consider different possible values for our parameter(s), <span class="math inline">\(p_B\)</span>, and determine how likely we would be to see our observed data in each case, <span class="math inline">\(\mathrm{Lik}(p_B)\)</span>. We’ll select as our estimate the value of <span class="math inline">\(p_B\)</span> for which our data is most likely. A <strong>likelihood</strong>  is a function that tells us how likely we are to observe our data for a given parameter value, <span class="math inline">\(p_B\)</span>. For a single family which has a girl followed by two boys, GBB, the likelihood function looks like:</p>
<p><span class="math display">\[\begin{equation*}
 \mathrm{Lik}(p_B) = P(G)P(B)P(B) = (1-p_B)p_B^2
\end{equation*}\]</span></p>
<div class="figure" style="text-align: center"><span id="fig:lik1"></span>
<img src="bookdown-BeyondMLR_files/figure-html/lik1-1.png" alt="Likehood function for GBB." width="90%" />
<p class="caption">
Figure 2.2: Likehood function for GBB.
</p>
</div>
<p>From the likelihood in Figure <a href="ch-beyondmost.html#fig:lik1">2.2</a>, when <span class="math inline">\(p_B\)</span> = 0.3 we see a family of a girl followed by two boys 6.3% (<span class="math inline">\(0.7\cdot0.3^2\)</span>) of the time. However, it indicates that we are much more likely to see our data if <span class="math inline">\(p_B\)</span> = 0.6 where the likelihood of GBB is <span class="math inline">\(0.4\cdot0.6^2\)</span> or 14.4%.</p>
<p>If the choice was between 0.3 and 0.6 for an estimate of <span class="math inline">\(p_B\)</span>, we’d choose 0.6. The “best” estimate of <span class="math inline">\(p_B\)</span> would be the value where we are most likely to see our data from all possible values between 0 and 1, which we refer to as the <strong>maximum likelihood estimate</strong> or MLE.  We can approximate an MLE using graphical or numerical approaches. Graphically, here it looks like the MLE is just above 0.6. In many, but not all, circumstances, we can obtain an MLE exactly using calculus. In this simple example, the MLE is 2/3. This is consistent with our intuition since 2 out of the 3 children are boys.</p>
<p>Suppose another family consisting of three girls is added to our data set. We’ve already seen that the Sex Unconditional Model multiplies probabilities to construct a likelihood because children are independent of one another. Extending this idea, families can be assumed to be independent of one another so that the likelihood for both families can be obtained by multiplication. With two families (GBB and GGG) our likelihood is now:</p>
<p><span class="math display">\[\begin{align*}
 \mathrm{Lik}(p_B) &amp;= P(GBB)P(GGG) \\
            &amp;= [(1-p_B)p_B^2][(1-p_B)^3] \\
            &amp;= (1-p_B)^4p_B^2
\end{align*}\]</span></p>
<p>A plot of this likelihood appears in Figure <a href="ch-beyondmost.html#fig:lik2">2.3</a>. It is right skewed with an MLE at approximately 0.3. Using calculus, we can show that the MLE is precisely 1/3 which is consistent with intuition given the 2 boys and 4 girls in our data.</p>
<div class="figure" style="text-align: center"><span id="fig:lik2"></span>
<img src="bookdown-BeyondMLR_files/figure-html/lik2-1.png" alt="Likelihood function for the data of 2 families (GBB and GGG). The solid line is at the MLE,  ${p}_B=1/3$" width="90%" />
<p class="caption">
Figure 2.3: Likelihood function for the data of 2 families (GBB and GGG). The solid line is at the MLE, <span class="math inline">\({p}_B=1/3\)</span>
</p>
</div>
<p>Turning now to our hypothetical data with 30 families who have a total of 50 children, we can create the likelihood contribution for each of the family compositions.</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:table2chp2">Table 2.2: </span>The likelihood factors for the hypothetical data set of n=50 children.
</caption>
<thead>
<tr>
<th style="text-align:left;">
Composition
</th>
<th style="text-align:left;">
Likelihood contribution for one family
</th>
<th style="text-align:right;">
Number of families
</th>
<th style="text-align:left;">
Likelihood contribution for multiple families
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
B
</td>
<td style="text-align:left;width: 4cm; ">
<span class="math inline">\(p_B\)</span>
</td>
<td style="text-align:right;">
6
</td>
<td style="text-align:left;width: 4cm; ">
<span class="math inline">\(p^6_B\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
G
</td>
<td style="text-align:left;width: 4cm; ">
(<span class="math inline">\(1-p_B\)</span>)
</td>
<td style="text-align:right;">
7
</td>
<td style="text-align:left;width: 4cm; ">
<span class="math inline">\((1-p_B)^7\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
BB
</td>
<td style="text-align:left;width: 4cm; ">
<span class="math inline">\(p^2_B\)</span>
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:left;width: 4cm; ">
<span class="math inline">\(p^{10}_B\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
BG
</td>
<td style="text-align:left;width: 4cm; ">
<span class="math inline">\(p_B(1-p_B)\)</span>
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:left;width: 4cm; ">
<span class="math inline">\(p^4_B(1-p_B)^4\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
GB
</td>
<td style="text-align:left;width: 4cm; ">
<span class="math inline">\((1-p_B)p_B\)</span>
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:left;width: 4cm; ">
<span class="math inline">\((1-p_B)^5 p^5_B\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
GGB
</td>
<td style="text-align:left;width: 4cm; ">
<span class="math inline">\((1-p_B)^2 p_B\)</span>
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:left;width: 4cm; ">
<span class="math inline">\((1-p_B)^2 p_B\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
GBB
</td>
<td style="text-align:left;width: 4cm; ">
<span class="math inline">\((1-p_B)p^2_B\)</span>
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:left;width: 4cm; ">
<span class="math inline">\((1-p_B)^2 p^4_B\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
Total
</td>
<td style="text-align:left;width: 4cm; ">
</td>
<td style="text-align:right;">
30
</td>
<td style="text-align:left;width: 4cm; ">
</td>
</tr>
</tbody>
</table>
<p>The likelihood function for the hypothetical data set can be found by taking the product of the entries in the last column of Table <a href="ch-beyondmost.html#tab:table2chp2">2.2</a> and simplifying.</p>
<p><span class="math display" id="eq:lik30">\[\begin{equation}
\begin{split}
 \mathrm{Lik}(p_B) &amp;= p_B^{6}(1-p_B)^{7}p_B^{10} \cdots \\
 &amp;= p_B^{30}(1-p_B)^{20}
\end{split}
\tag{2.1} 
\end{equation}\]</span></p>
<p>It should be obvious that the likelihood for this Sex Unconditional Model (the coin flipping model) has the simple form:</p>
<p><span class="math display">\[\begin{equation*}
\mathrm{Lik}(p_B) = p_B^{n_\textrm{Boys}}(1-p_B)^{n_\textrm{Girls}}
\end{equation*}\]</span></p>
<p>and as we asserted above, the MLE will be the (number of boys)/(number of kids) or 30/50 here. Now, more formally, we demonstrate how we use the likelihood principle to approximate the MLE or determine it exactly.</p>
</div>
<div id="findMLE.sec" class="section level3">
<h3><span class="header-section-number">2.4.2</span> Finding MLEs</h3>
<div id="MLEgph.sec" class="section level4">
<h4><span class="header-section-number">2.4.2.1</span> Graphically approximating an MLE</h4>
<div class="figure" style="text-align: center"><span id="fig:lik4"></span>
<img src="bookdown-BeyondMLR_files/figure-html/lik4-1.png" alt="Likelihood and log-likelihood functions for 50 children (30 boys and 20 girls) and for 1000 children (600 boys and 400 girls)." width="90%" />
<p class="caption">
Figure 2.4: Likelihood and log-likelihood functions for 50 children (30 boys and 20 girls) and for 1000 children (600 boys and 400 girls).
</p>
</div>
<p>Figure <a href="ch-beyondmost.html#fig:lik4">2.4</a>(a) is the likelihood for the data set of 50 children. The height of each point is the likelihood and the possible values for <span class="math inline">\(p_B\)</span> appear across the horizontal axis. It appears that our data is most likely when <span class="math inline">\(p_B = 0.6\)</span> as we would expect. Note that the log of the likelihood function in Figure <a href="ch-beyondmost.html#fig:lik4">2.4</a>(b) is maximized at the same spot: <span class="math inline">\(p_B = 0.6\)</span>; we will see advantages of using log likelihoods a bit later. Figures <a href="ch-beyondmost.html#fig:lik4">2.4</a>(c) and (d) are also maximized at <span class="math inline">\(p_B = 0.6\)</span>, but they illustrate less variability and a sharper peak since there is more data (although the same proportions of boys and girls).</p>
</div>
<div id="numerically-approximating-an-mle" class="section level4">
<h4><span class="header-section-number">2.4.2.2</span> Numerically approximating an MLE</h4>
<p>Here a grid search is used with the software package R to find maximum likelihood estimates, something that can be done with most software. A grid search specifies a set of finite possible values for <span class="math inline">\(p_B\)</span> and then the likelihood, <span class="math inline">\(\mathrm{Lik}(p_B)\)</span>, is computed for each of the possible values. First, we define a relatively coarse grid by specifying 50 values for <span class="math inline">\(p_B\)</span> and then computing how likely we would see our data for each of these possible values. The second example uses a finer grid, 1,000 values for <span class="math inline">\(p_B\)</span>, which allows us to determine a better (more precise) approximation of the MLE. In addition, most packages, like R, have an optimize function which can also be used to obtain MLEs. Both of these approaches are illustrated in the following code.</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="ch-beyondmost.html#cb32-1"></a>Lik.f &lt;-<span class="st"> </span><span class="cf">function</span>(nBoys,nGirls,nGrid){</span>
<span id="cb32-2"><a href="ch-beyondmost.html#cb32-2"></a>    <span class="co"># possible values for prob a boy is born</span></span>
<span id="cb32-3"><a href="ch-beyondmost.html#cb32-3"></a>    pb &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">length =</span> nGrid)   </span>
<span id="cb32-4"><a href="ch-beyondmost.html#cb32-4"></a>    lik &lt;-<span class="st"> </span>pb<span class="op">^</span>{nBoys} <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>pb)<span class="op">^</span>{nGirls}</span>
<span id="cb32-5"><a href="ch-beyondmost.html#cb32-5"></a>    <span class="co"># maximum likelihood over nGrid values of pb</span></span>
<span id="cb32-6"><a href="ch-beyondmost.html#cb32-6"></a>    <span class="kw">max</span>(lik)             </span>
<span id="cb32-7"><a href="ch-beyondmost.html#cb32-7"></a>    <span class="co"># value of pb where likelihood maximized</span></span>
<span id="cb32-8"><a href="ch-beyondmost.html#cb32-8"></a>    pb[lik<span class="op">==</span><span class="kw">max</span>(lik)]    </span>
<span id="cb32-9"><a href="ch-beyondmost.html#cb32-9"></a>  }</span>
<span id="cb32-10"><a href="ch-beyondmost.html#cb32-10"></a><span class="co"># estimated maximum likelihood estimator for p_B</span></span>
<span id="cb32-11"><a href="ch-beyondmost.html#cb32-11"></a><span class="kw">Lik.f</span>(<span class="dt">nBoys =</span> <span class="dv">30</span>, <span class="dt">nGirls =</span> <span class="dv">20</span>, <span class="dt">nGrid =</span> <span class="dv">50</span>) </span></code></pre></div>
<pre><code>## [1] 0.5918</code></pre>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="ch-beyondmost.html#cb34-1"></a><span class="co"># more precise MLE for p_B based on finer grid (more points)</span></span>
<span id="cb34-2"><a href="ch-beyondmost.html#cb34-2"></a><span class="kw">Lik.f</span>(<span class="dt">nBoys =</span> <span class="dv">30</span>, <span class="dt">nGirls =</span> <span class="dv">20</span>, <span class="dt">nGrid =</span> <span class="dv">1000</span>)</span></code></pre></div>
<pre><code>## [1] 0.5996</code></pre>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="ch-beyondmost.html#cb36-1"></a><span class="co">## Another approach: using R&#39;s optimize command</span></span>
<span id="cb36-2"><a href="ch-beyondmost.html#cb36-2"></a><span class="co">##   Note that the log-likelihood is optimized here</span></span>
<span id="cb36-3"><a href="ch-beyondmost.html#cb36-3"></a>oLik.f &lt;-<span class="st"> </span><span class="cf">function</span>(pb){</span>
<span id="cb36-4"><a href="ch-beyondmost.html#cb36-4"></a>    <span class="kw">return</span>(<span class="dv">30</span><span class="op">*</span><span class="kw">log</span>(pb) <span class="op">+</span><span class="st"> </span><span class="dv">20</span><span class="op">*</span><span class="kw">log</span>(<span class="dv">1</span><span class="op">-</span>pb))</span>
<span id="cb36-5"><a href="ch-beyondmost.html#cb36-5"></a>  }</span>
<span id="cb36-6"><a href="ch-beyondmost.html#cb36-6"></a><span class="kw">optimize</span>(oLik.f, <span class="dt">interval=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>), <span class="dt">maximum=</span><span class="ot">TRUE</span>)</span></code></pre></div>
<pre><code>## $maximum
## [1] 0.6
## 
## $objective
## [1] -33.65</code></pre>
</div>
<div id="calc-sec" class="section level4">
<h4><span class="header-section-number">2.4.2.3</span> MLEs using calculus (Optional)</h4>
<p>Calculus may provide another way to determine an MLE. Here, we can ascertain the value of <span class="math inline">\(p_B\)</span> where the likelihood is a maximum by using the first derivative of the likelihood with respect to <span class="math inline">\(p_B\)</span>. We obtain the first derivative using the Product Rule, set it to 0, solve for <span class="math inline">\(p_B\)</span>, and verify that a maximum occurs there.</p>
<p><span class="math display">\[\begin{equation*}
\frac{d}{dp_B}p_B^{30}(1-p_B)^{20} = 30p_B^{29}(1-p_B)^{20}-p^{30}_B20(1-p_B)^{19} = 0
\end{equation*}\]</span></p>
<p>This approach would produce <span class="math inline">\(p_B = .60\)</span> as we intuited earlier; however, we’ll find that likelihoods can get a lot more complicated than this one and there is a simpler way to proceed. This simpler approach is based on the fact that the log of a likelihood is maximized at the same value of <span class="math inline">\(p_B\)</span> as the likelihood. Likelihoods are typically products which require the application of the Product Rule when differentiating, whereas log-likelihoods are sums which are much easier to differentiate. In addition, likelihoods can become tiny with large data sets. So we can take the log of the likelihood, differentiate it, and find the value of <span class="math inline">\(p_B\)</span> where the log-likelihood is a maximum and have the MLE for <span class="math inline">\(p_B\)</span>. We observed this visually in Figure <a href="ch-beyondmost.html#fig:lik4">2.4</a>, where (a) and (b) are maximized at the same <span class="math inline">\(p_B\)</span> (as are (c) and (d)). For the data set with 50 children:</p>
<p><span class="math display" id="eq:dlogLik50">\[\begin{align*}
 \mathrm{Lik}(p_B)                      &amp;= p_B^{30}(1-p_B)^{20} \\
 \log(\mathrm{Lik}(p_B))                &amp;= 30\log(p_B)+20\log(1-p_B) \\
 \frac{d}{dp_B} \log(\mathrm{Lik}(p_B)) &amp;= \frac{30}{p_B} - \frac{20}{1-p_B} = 0
 \tag{2.2}
\end{align*}\]</span></p>
<p>It is now straightforward to determine that the log-likelihood is maximized when <span class="math inline">\(p_B = 3/5.\)</span> We say that the MLE is <span class="math inline">\(\hat{p}_B = 0.6\)</span>. This is the exact estimate that was approximated above.</p>
</div>
<div id="how-does-sample-size-affect-the-likelihood" class="section level4">
<h4><span class="header-section-number">2.4.2.4</span> How does sample size affect the likelihood?</h4>
<p>Consider two hypothetical cases under the Sex Unconditional Model:</p>
<p><strong>Hypothetical Case 1: n = 50 children with 30 boys and 20 girls</strong> In previous sections, we found the MLE, <span class="math inline">\(\hat{p}_B=0.6.\)</span></p>
<p><strong>Hypothetical Case 2: n = 1000 children with 600 boys and 400 girls</strong> Our earlier work suggests that the MLE here is also <span class="math inline">\(\hat{p}_B=0.6.\)</span></p>
<p>The graphs of the likelihoods and log-likelihoods for these two cases in Figure <a href="ch-beyondmost.html#fig:lik4">2.4</a> give us an idea of how the increase in the sample size affects the precision of our estimates. The likelihoods and log-likelihoods for the two sample sizes have similar forms; however, the graphs with the larger sample size are much narrower, reflecting the greater precision we have with more data. With only 50 children there is a wide range of <span class="math inline">\(p_B\)</span> values that lead to values of the log-likelihood near its maximum, so it’s less clear what the optimal <span class="math inline">\(p_B\)</span> is. As we have seen in statistics courses before, a larger sample size will result in less variation in our estimates, thereby affecting the power of hypothesis tests and the width of the confidence intervals.</p>
</div>
</div>
<div id="summary" class="section level3">
<h3><span class="header-section-number">2.4.3</span> Summary</h3>
<p>Using likelihoods to find estimates of parameters is conceptually intuitive—select the estimate for your parameter where your data is most likely. Often MLEs make a lot of intuitive sense in the context of a problem as well; for example, here the MLE for the probability of a boy is the observed proportion of boys in the data. It may seem like a lot of work for such an obvious result, but MLEs have some nice, useful theoretical properties, and we’ll see that many more complex models can be fit using the principle of maximum likelihood.</p>
<p>In summary, we constructed a likelihood that reflected features of our Sex Unconditional Model, then we approximated the parameter value for which our data is most likely using a graph or software, or we determined our optimal parameter value exactly using calculus. You may not be familiar with calculus, yet the concept is clear from the graphs: just find the value of <span class="math inline">\(p_B\)</span> where the likelihood or log likelihood is a maximum. Our “best” estimate for <span class="math inline">\(p_B\)</span>, the MLE, is where our data is most likely to be observed.</p>
<p>Work to understand the <em>idea</em> of a likelihood. Likelihoods are the foundation upon which estimates are obtained and models compared for most of this course. Do not be overly concerned with calculus and computation at this point.</p>
</div>
<div id="is-a-likelihood-a-probability-function-optional" class="section level3">
<h3><span class="header-section-number">2.4.4</span> Is a likelihood a probability function? (Optional)</h3>
<p>No. Even though we use probabilities to construct likelihoods, a likelihood is not a probability function. A probability function fixes parameter values and take as inputs possible outcomes, returning the probability of seeing different outcomes given the parameter value. For example, you flip a loaded coin which comes up heads 25% of the time. After 5 flips, you observe the outcome of three heads and two tails. A <em>probability function</em> provides the probability of observing (3H,2T) when <span class="math inline">\(p_H=0.25\)</span>. If you flip this same coin another 5 times and observe all tails (5T), the probability function provides the probability of (5T) when <span class="math inline">\(p_H=0.25\)</span>.</p>
<p>In contrast, a likelihood is constructed by fixing the data, say (3H,2T). It takes as input <em>possible parameter values</em> and returns the probability of seeing the fixed data for each parameter value. For example, the likelihood will provide the chance of seeing the data (3H,2T) if <span class="math inline">\(p_H=0.6\)</span>, the chance of seeing the data (3H,2T) if <span class="math inline">\(p_H=0.3\)</span>, and so on. With the likelihood we can find the value of <span class="math inline">\(p_H\)</span> where we are most likely to see our data.</p>
</div>
</div>
<div id="sex_conditional.sec" class="section level2">
<h2><span class="header-section-number">2.5</span> Model 2: Sex Conditional Model (Sex Bias)</h2>
<p>Our first research question involves determining whether sex runs in the family. Do families who already have boys tend to have more additional boys than expected by chance, and do families who already have girls tend to have more additional girls than expected by chance? What do you think? And how could we use a statistical model to investigate this phenomenon? There are a number of different ways to construct a model for this question. Here’s one possibility.</p>
<div id="model-specification" class="section level3">
<h3><span class="header-section-number">2.5.1</span> Model Specification</h3>
<p>Unlike the previous model, the <span class="math inline">\(p_B\)</span> in a Sex Conditional Model <em>depends</em> on existing family compositions. We introduce <strong>conditional probabilities</strong>  and conditional notation to make the dependence explicit. One way to interpret the notation <span class="math inline">\(P(A|B)\)</span> is the “probability of A <em>given</em> B has occurred.” Another way to read this notation is the “probability of A <em>conditional</em> on B.” Here, let <span class="math inline">\(p_{B|N}\)</span> represent the probability the next child is a boy given that there are equal numbers of boys and girls (sex-neutral) in the existing family. Let <span class="math inline">\(p_{B|\textrm{B Bias}}\)</span> represent the probability the next child is a boy if the family is boy-biased; i.e., there are more boys than girls prior to this child. Similarly, let <span class="math inline">\(p_{B|\textrm{G Bias}}\)</span> represent the probability the next child is a boy if the family is girl-biased; i.e., there are more girls than boys prior to this child.</p>
<p>Before we are mired in notation and calculus, let’s think about how these conditional probabilities can be used to describe sex running in families. While we only had one parameter, <span class="math inline">\(p_B\)</span>, to estimate in the Sex Unconditional Model, here we have three parameters: <span class="math inline">\(p_{B|N}\)</span>, <span class="math inline">\(p_{B|\textrm{B Bias}}\)</span>, and <span class="math inline">\(p_{B|\textrm{G Bias}}\)</span>. Clearly if all three of these probabilities are equal, the probability a child is a boy does not depend upon the existing gender composition of the family and there is no evidence of sex running in families. A conditional probability <span class="math inline">\(p_{B|\textrm{B Bias}}\)</span> that is larger than <span class="math inline">\(p_{B|N}\)</span> suggests families with more boys are more likely to produce additional boys in contrast to families with equal boys and girls. This finding would support the theory of “boys run in families.” An analogous argument holds for girls. In addition, comparisons of <span class="math inline">\(p_{B|\textrm{B Bias}}\)</span> and <span class="math inline">\(p_{B|\textrm{G Bias}}\)</span> to the parameter estimate <span class="math inline">\(p_B\)</span> from the Sex Unconditional Model may be interesting and can be performed using likelihoods.</p>
<p>While it may seem that including families with a single child (singletons) would not be helpful for assessing whether there is a preponderance of one sex or another in families, in fact singleton families would be helpful in estimating <span class="math inline">\(p_{B|N}\)</span> because singletons join “neutral families.”</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:table3chp2">Table 2.3: </span>Family contributions to the likelihood for a Sex Conditional Model using a hypothetical data set of n=50 children from 30 families.
</caption>
<thead>
<tr>
<th style="text-align:left;">
Composition
</th>
<th style="text-align:left;">
Likelihood contribution
</th>
<th style="text-align:left;">
Prior Status
</th>
<th style="text-align:right;">
Number of families
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
B
</td>
<td style="text-align:left;">
<span class="math inline">\(p_{B|N}\)</span>
</td>
<td style="text-align:left;">
neutral
</td>
<td style="text-align:right;">
6
</td>
</tr>
<tr>
<td style="text-align:left;">
G
</td>
<td style="text-align:left;">
<span class="math inline">\((1-p_{B|N})\)</span>
</td>
<td style="text-align:left;">
neutral
</td>
<td style="text-align:right;">
7
</td>
</tr>
<tr>
<td style="text-align:left;">
BB
</td>
<td style="text-align:left;">
<span class="math inline">\((p_{B|N}) (p_{B|\textrm{B Bias}})\)</span>
</td>
<td style="text-align:left;">
neutral, boy bias
</td>
<td style="text-align:right;">
5
</td>
</tr>
<tr>
<td style="text-align:left;">
BG
</td>
<td style="text-align:left;">
<span class="math inline">\((p_{B|N}) (1-p_{B|\textrm{B Bias}})\)</span>
</td>
<td style="text-align:left;">
neutral, boy bias
</td>
<td style="text-align:right;">
4
</td>
</tr>
<tr>
<td style="text-align:left;">
GB
</td>
<td style="text-align:left;">
<span class="math inline">\((1-p_{B|N}) (p_{B|\textrm{G Bias}})\)</span>
</td>
<td style="text-align:left;">
neutral, girl bias
</td>
<td style="text-align:right;">
5
</td>
</tr>
<tr>
<td style="text-align:left;">
GGB
</td>
<td style="text-align:left;">
<span class="math inline">\((1-p_{B|N}) (1-p_{B|\textrm{G Bias}}) (p_{B|\textrm{G Bias}})\)</span>
</td>
<td style="text-align:left;">
neutral, girl bias, girl bias
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:left;">
GBB
</td>
<td style="text-align:left;">
<span class="math inline">\((1-p_{B|N}) (p_{B|\textrm{G Bias}}) (p_{B|N})\)</span>
</td>
<td style="text-align:left;">
neutral, girl bias, neutral
</td>
<td style="text-align:right;">
2
</td>
</tr>
<tr>
<td style="text-align:left;">
Total
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:right;">
30
</td>
</tr>
</tbody>
</table>
</div>
<div id="application-to-hypothetical-data" class="section level3">
<h3><span class="header-section-number">2.5.2</span> Application to Hypothetical Data</h3>
<p>Using the family composition data for 50 children in the 30 families that appears in Table <a href="ch-beyondmost.html#tab:table3chp2">2.3</a>, we construct a likelihood. The six singleton families with only one boy contribute <span class="math inline">\(p_{B|N}^6\)</span> to the likelihood and the seven families with only one girl contribute <span class="math inline">\(p_{G|N}^7\)</span> or <span class="math inline">\((1-p_{B|N})^7\)</span>. [Why do we use <span class="math inline">\(1-p_{B|N}\)</span> instead of <span class="math inline">\(p_{G|N}\)</span>?] There are five families with two boys each with probability <span class="math inline">\((p_{B|N})(p_{B|\textrm{B Bias}})\)</span> contributing:</p>
<p><span class="math display">\[
[(p_{B|N})(p_{B|\textrm{B Bias}})]^{5}.
\]</span></p>
<p>We construct the likelihood using data from all 30 families assuming families are independent to get:</p>
<p><span class="math display" id="eq:lik50">\[\begin{equation}
\begin{split}
 \mathrm{Lik}(p_{B|N},\ p_{B|\textrm{B Bias}},\ p_{B|\textrm{G Bias}}) &amp;= 
 \big[(p_{B|N})^{17}
 (1-p_{B|N})^{15}
 (p_{B|\textrm{B Bias}})^{5} \\
 &amp;{}(1-p_{B|\textrm{B Bias}})^{4}
 (p_{B|\textrm{G Bias}})^{8}
 (1-p_{B|\textrm{G Bias}}) \big]
\end{split}
\tag{2.3}
\end{equation}\]</span></p>
<p>A couple of points are worth noting. First, there are 50 factors in the likelihood corresponding to the 50 children in these 30 families. Second, in the Sex Unconditional example we only had one parameter, <span class="math inline">\(p_{B}\)</span>; here we have three parameters. This likelihood does not simplify like the Sex Unconditional Model to one that is a product of only two powers: one of <span class="math inline">\(p_B\)</span> and the other of <span class="math inline">\(1-p_B\)</span>. Yet, the basic idea we discussed regarding using a likelihood to find parameter estimates is the same. To obtain the MLEs, we need to find the combination of values for our three parameters where the data is most likely to be observed. Conceptually, we are trying different combinations of possible values for these three parameters, one after another, until we find <em>the</em> combination where the likelihood is a maximum. It will not be as easy to graph this likelihood and we will need multivariable calculus to locate the optimal combination of parameter values where the likelihood is a maximum. In this text, we do not assume you know multivariable calculus, but we do want you to retain the concepts associated with maximum likelihood estimates. In practice, we use software to obtain MLEs.</p>
<p>With calculus, we can take partial derivatives of the likelihood with respect to each parameter assuming the other parameters are fixed. As we saw in Section <a href="ch-beyondmost.html#calc-sec">2.4.2.3</a>, differentiating the log of the likelihood often makes things easier. This same approach is recommended here. Set each partial derivative to 0 and solve for all parameters simultaneously.</p>
<p>Knowing that it is easier to work with log-likelihoods, let’s take the log of the likelihood we constructed in Equation <a href="ch-beyondmost.html#eq:lik50">(2.3)</a>.</p>
<p><span class="math display">\[\begin{multline*}
\log (\mathrm{Lik}(p_{B|N},\ p_{B|\textrm{B Bias}},\ p_{B|\textrm{G Bias}})) = 
        17\log(p_{B|N})+15\log(1-p_{B|N}) \\
        +5\log(p_{B|\textrm{B Bias}})+4\log(1-p_{B|\textrm{B Bias}}) 
        +8\log(p_{B|\textrm{G Bias}})+1\log(1-p_{B|\textrm{G Bias}})
\end{multline*}\]</span></p>
<p>Taking a partial derivative with respect to <span class="math inline">\(p_{B|N}\)</span></p>
<p><span class="math display">\[\begin{align*}
\frac{17}{p_{B|N}}  - \frac{15}{1-p_{B|N}}&amp;=0 \\
\hat{p}_{B|N}&amp;= \frac{17}{32} \\
&amp;=0.53 \\
\end{align*}\]</span></p>
<p>This estimate follows naturally. First consider all of the children who enter into a family with an equal number of boys and girls. From Table <a href="ch-beyondmost.html#tab:table3chp2">2.3</a>, we can see there are 32 such children (30 are first kids and 2 are third kids in families with 1 boy and 1 girl). Of those children, 17 are boys. So, given that a child joins a sex neutral family, the chance they are a boy is 17/32. Similar calculations for <span class="math inline">\(p_{B|\textrm{B Bias}}\)</span> and <span class="math inline">\(p_{B|\textrm{G Bias}}\)</span> yield:</p>
<p><span class="math display">\[\begin{align*}
 \hat{p}_{B|N} &amp;= 17/32 = 0.53  \\  
 \hat{p}_{B|\textrm{B Bias}} &amp;= 5/9 = 0.56  \\
 \hat{p}_{B|\textrm{G Bias}} &amp;= 8/9 = 0.89  
\end{align*}\]</span></p>
<p>If we anticipate any “sex running in families” effect, we would expect <span class="math inline">\(p_{B|\textrm{B Bias}}\)</span> to be larger than the the probability of a boy in the neutral setting, <span class="math inline">\(p_{B|N}\)</span>. In our small hypothetical example, <span class="math inline">\(\hat{p}_{B|\textrm{B Bias}}\)</span> is slightly greater than 0.53, providing light support for the “sex runs in families” theory when it comes to boys. What about girls? Do families with more girls than boys tend to have a greater probability of having a girl? We found that the MLE for the probability of a girl in a girl biased setting is 1-0.89=0.11.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> This data does not provide evidence that girls run in families since <span class="math inline">\(\hat{p}_{G|G_{bias}} = 0.11 &lt; \hat{p}_{G|N}=0.47\)</span>; there is a markedly lower probability of a girl if the family is already girl biased. This data is, however, hypothetical. Let’s take a look at some real data and see what we find.</p>
</div>
</div>
<div id="case-study-analysis-of-the-nlsy-data" class="section level2">
<h2><span class="header-section-number">2.6</span> Case Study: Analysis of the NLSY data</h2>
<div id="model-building-plan" class="section level3">
<h3><span class="header-section-number">2.6.1</span> Model Building Plan</h3>
<p>You should now have a feel for using the Likelihood Principle to obtain estimates of parameters using family gender composition data. Next, these ideas will be applied to the NLSY data summarized in Table 2 of <span class="citation">(Rodgers and Doughty <a href="#ref-Rodgers2001" role="doc-biblioref">2001</a>)</span>. In addition to considering the Sex Unconditional and Conditional Models, we investigate some models that incorporate choices couples may make about when to stop having more children.</p>
</div>
<div id="EDA.sec" class="section level3">
<h3><span class="header-section-number">2.6.2</span> Family Composition of Boys and Girls, NLSY: Exploratory Data Analysis</h3>
<p>We begin by performing an exploratory data analysis aimed at shedding some light on our research questions. We are looking for clues as to which of our models is most plausible. The first statistic of interest is the proportion of boys in the sample. There are 5,416 boys out of the 10,672 children or a proportion of .507 boys. While this proportion is very close to .500, it is worth noting that a difference of .007 could be meaningful in population terms.</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:table4chp2">Table 2.4: </span>Number of families and children in families with given composition in NLSY data. Sex ratio and proportion males are given by family size.
</caption>
<thead>
<tr>
<th style="text-align:left;">
Family Composition
</th>
<th style="text-align:right;">
Number of families
</th>
<th style="text-align:right;">
Number of children
</th>
<th style="text-align:left;">
males : females
</th>
<th style="text-align:left;">
p_B
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;width: 3cm; ">
B
</td>
<td style="text-align:right;width: 3cm; ">
930
</td>
<td style="text-align:right;width: 3cm; ">
930
</td>
<td style="text-align:left;width: 3cm; ">
97 boys to 100 girls
</td>
<td style="text-align:left;width: 3cm; ">
0.494
</td>
</tr>
<tr>
<td style="text-align:left;width: 3cm; ">
G
</td>
<td style="text-align:right;width: 3cm; ">
951
</td>
<td style="text-align:right;width: 3cm; ">
951
</td>
<td style="text-align:left;width: 3cm; ">
</td>
<td style="text-align:left;width: 3cm; ">
</td>
</tr>
<tr>
<td style="text-align:left;width: 3cm; ">
BB
</td>
<td style="text-align:right;width: 3cm; ">
582
</td>
<td style="text-align:right;width: 3cm; ">
1164
</td>
<td style="text-align:left;width: 3cm; ">
104 boys to 100 girls
</td>
<td style="text-align:left;width: 3cm; ">
0.511
</td>
</tr>
<tr>
<td style="text-align:left;width: 3cm; ">
BG
</td>
<td style="text-align:right;width: 3cm; ">
666
</td>
<td style="text-align:right;width: 3cm; ">
1332
</td>
<td style="text-align:left;width: 3cm; ">
</td>
<td style="text-align:left;width: 3cm; ">
</td>
</tr>
<tr>
<td style="text-align:left;width: 3cm; ">
GB
</td>
<td style="text-align:right;width: 3cm; ">
666
</td>
<td style="text-align:right;width: 3cm; ">
1332
</td>
<td style="text-align:left;width: 3cm; ">
</td>
<td style="text-align:left;width: 3cm; ">
</td>
</tr>
<tr>
<td style="text-align:left;width: 3cm; ">
GG
</td>
<td style="text-align:right;width: 3cm; ">
530
</td>
<td style="text-align:right;width: 3cm; ">
1060
</td>
<td style="text-align:left;width: 3cm; ">
</td>
<td style="text-align:left;width: 3cm; ">
</td>
</tr>
<tr>
<td style="text-align:left;width: 3cm; ">
BBB
</td>
<td style="text-align:right;width: 3cm; ">
186
</td>
<td style="text-align:right;width: 3cm; ">
558
</td>
<td style="text-align:left;width: 3cm; ">
104 boys to 100 girls
</td>
<td style="text-align:left;width: 3cm; ">
0.510
</td>
</tr>
<tr>
<td style="text-align:left;width: 3cm; ">
BBG
</td>
<td style="text-align:right;width: 3cm; ">
177
</td>
<td style="text-align:right;width: 3cm; ">
531
</td>
<td style="text-align:left;width: 3cm; ">
</td>
<td style="text-align:left;width: 3cm; ">
</td>
</tr>
<tr>
<td style="text-align:left;width: 3cm; ">
BGG
</td>
<td style="text-align:right;width: 3cm; ">
173
</td>
<td style="text-align:right;width: 3cm; ">
519
</td>
<td style="text-align:left;width: 3cm; ">
</td>
<td style="text-align:left;width: 3cm; ">
</td>
</tr>
<tr>
<td style="text-align:left;width: 3cm; ">
BGB
</td>
<td style="text-align:right;width: 3cm; ">
148
</td>
<td style="text-align:right;width: 3cm; ">
444
</td>
<td style="text-align:left;width: 3cm; ">
</td>
<td style="text-align:left;width: 3cm; ">
</td>
</tr>
<tr>
<td style="text-align:left;width: 3cm; ">
GBB
</td>
<td style="text-align:right;width: 3cm; ">
151
</td>
<td style="text-align:right;width: 3cm; ">
453
</td>
<td style="text-align:left;width: 3cm; ">
</td>
<td style="text-align:left;width: 3cm; ">
</td>
</tr>
<tr>
<td style="text-align:left;width: 3cm; ">
GGB
</td>
<td style="text-align:right;width: 3cm; ">
125
</td>
<td style="text-align:right;width: 3cm; ">
375
</td>
<td style="text-align:left;width: 3cm; ">
</td>
<td style="text-align:left;width: 3cm; ">
</td>
</tr>
<tr>
<td style="text-align:left;width: 3cm; ">
GBG
</td>
<td style="text-align:right;width: 3cm; ">
182
</td>
<td style="text-align:right;width: 3cm; ">
546
</td>
<td style="text-align:left;width: 3cm; ">
</td>
<td style="text-align:left;width: 3cm; ">
</td>
</tr>
<tr>
<td style="text-align:left;width: 3cm; ">
GGG
</td>
<td style="text-align:right;width: 3cm; ">
159
</td>
<td style="text-align:right;width: 3cm; ">
477
</td>
<td style="text-align:left;width: 3cm; ">
</td>
<td style="text-align:left;width: 3cm; ">
</td>
</tr>
</tbody>
</table>
<p>Table <a href="ch-beyondmost.html#tab:table4chp2">2.4</a> displays family composition data for the 5,626 families with one, two, or three children in the NLSY data set. This dataset includes 10,672 children. Because our interest centers on the proportion of males, let’s calculate sex ratios and proportions of males for each family size. For one-child families the male to female ratio is less than one (97 males:100 females) whereas both two- and three-child families have ratios of 104 boys to 100 girls, what we may expect in a population which favors males. While our research questions do not specifically call for these measures stratified by family size, it still provides us with an idea of gender imbalance in the data.</p>
<p>Table <a href="ch-beyondmost.html#tab:table6chp2">2.5</a> provides insight into whether sex runs in families if the probability of a boy is 0.5. Simple probability suggests that the percentage of 2-child families with all the same sex would be 50% (BB or GG vs. BG or GB) but in our data we see only 45%. For 3-child families, we have 8 possible orderings of boys and girls and so we would expect 2 out of the 8 orderings (25%) to be of the same sex (BBB or GGG), but in fact 27% have the same sex among the 3-children families. These results do not provide overwhelming evidence of sex running in families. There are some potentially complicating factors: the probability of a boy may not be 0.5 or couples may be waiting for a boy or a girl or both.</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:table6chp2">Table 2.5: </span>Proportion of families in NLSY data with all the same sex by number of children in the family. Note that 1-child families are all homogeneous with respect to sex so we look at 2- and 3- child families.
</caption>
<thead>
<tr>
<th style="text-align:left;">
Number of children
</th>
<th style="text-align:right;">
Number of families
</th>
<th style="text-align:right;">
Number with all same sex
</th>
<th style="text-align:left;">
Percent with same sex
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Two Children
</td>
<td style="text-align:right;">
2444
</td>
<td style="text-align:right;">
1112
</td>
<td style="text-align:left;">
45%
</td>
</tr>
<tr>
<td style="text-align:left;">
Three Children
</td>
<td style="text-align:right;">
1301
</td>
<td style="text-align:right;">
345
</td>
<td style="text-align:left;">
27%
</td>
</tr>
</tbody>
</table>
<p>Table <a href="ch-beyondmost.html#tab:table7chp2">2.6</a> contains the number of families by size and the percentage of those which are families with one boy who is last. Some of these families may have “waited” for a boy and then quit childbearing after a boy was born. We see the proportion of one child families with a boy is slightly less than the 50% expected. We’d expect one out of four, or 25%, of 2-child family configurations to have one boy last and there is 27% in our dataset. Only 8.6% of 3-child families have one boy last, but in theory we would expect one out of eight or 12.5% of 3-child families to have one boy last. So if, in fact, the probability of a boy is 50%, there does not appear to be evidence supporting the notion that families wait for a boy.</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:table7chp2">Table 2.6: </span>Proportion of families in NLSY data with only one boy who is born last.
</caption>
<thead>
<tr>
<th style="text-align:left;">
Number of children
</th>
<th style="text-align:right;">
Number of families
</th>
<th style="text-align:right;">
Number with one boy last
</th>
<th style="text-align:left;">
Percent with boy last
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
One Child
</td>
<td style="text-align:right;">
1881
</td>
<td style="text-align:right;">
930
</td>
<td style="text-align:left;">
49.4%
</td>
</tr>
<tr>
<td style="text-align:left;">
Two Children
</td>
<td style="text-align:right;">
2444
</td>
<td style="text-align:right;">
666
</td>
<td style="text-align:left;">
27.2%
</td>
</tr>
<tr>
<td style="text-align:left;">
Three Children
</td>
<td style="text-align:right;">
1301
</td>
<td style="text-align:right;">
125
</td>
<td style="text-align:left;">
8.6%
</td>
</tr>
</tbody>
</table>
<p>There are many other ways to formulate and explore the idea that sex runs in families or that couples wait for a boy (or a girl). See <span class="citation">Rodgers and Doughty (<a href="#ref-Rodgers2001" role="doc-biblioref">2001</a>)</span> for other examples.</p>
</div>
<div id="likelihood-for-the-sex-unconditional-model-the-nlsy-data" class="section level3">
<h3><span class="header-section-number">2.6.3</span> Likelihood for the Sex Unconditional Model: the NLSY data</h3>
<p>We construct a likelihood for the Sex Unconditional Model for the one-, two- and three-child families from the NLSY. See Table <a href="ch-beyondmost.html#tab:table4chp2">2.4</a> for the frequencies of each gender composition.</p>
<p>Families with different compositions will contribute different factors to the likelihood. For example, Table <a href="ch-beyondmost.html#tab:sexuncondmodel">2.7</a> shows a sample of contributions for a few family compositions, where coefficients come from Table <a href="ch-beyondmost.html#tab:table4chp2">2.4</a>.</p>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:sexuncondmodel">Table 2.7: </span>Contributions to the likelihood function for the Sex Unconditional Model for a sample of family compositions from the NLSY data
</caption>
<thead>
<tr>
<th style="text-align:left;">
Family composition
</th>
<th style="text-align:left;">
Likelihood contribution
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;width: 5cm; ">
G
</td>
<td style="text-align:left;width: 5cm; ">
<span class="math inline">\((1-p_B)^{951}\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;width: 5cm; ">
GB
</td>
<td style="text-align:left;width: 5cm; ">
<span class="math inline">\((1-p_B)^{666}p_B^{666}\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;width: 5cm; ">
BGB
</td>
<td style="text-align:left;width: 5cm; ">
<span class="math inline">\(p_B^{2*148}(1-p_B)^{148}\)</span>
</td>
</tr>
</tbody>
</table>
<p>Now we create the entire likelihood for our data under the Sex Unconditional Model.</p>
<p><span class="math display">\[\begin{align*}
 \mathrm{Lik}(p_B) &amp;= p_B^{930}p_G^{951}p_{BB}^{582} \cdots p_{BBG}^{177} \cdots p_{GGG}^{159} \\
 &amp;= p_B^{930+2*582+666+666+\cdots+182}(1-p_B)^{951+666+666+2*530+\cdots+3*159} \\
 &amp;=  p_B^{5416}(1-p_B)^{5256}
\end{align*}\]</span></p>
<p>This very simple likelihood implies that each child contributes a factor of the form <span class="math inline">\(p_B\)</span> or <span class="math inline">\(1-p_B\)</span>. Given that there are 10,672 children, what would be your best guess of the estimated probability of a boy for this model? We can determine the MLE for <span class="math inline">\(p_B\)</span> using our previous work.</p>
<p><span class="math display">\[\begin{equation*}
\begin{split}
 \hat{p_B} &amp;= \frac{nBoys}{nBoys + nGirls} \\
 &amp; =  \frac{5416}{5416+5256} \\
 &amp;= 0.507
\end{split}
\end{equation*}\]</span></p>
</div>
<div id="sex-cond-lik" class="section level3">
<h3><span class="header-section-number">2.6.4</span> Likelihood for the Sex Conditional Model</h3>
<p>The contribution to a Sex Conditional Model likelihood for the same family compositions we considered in the previous section appear in Table <a href="ch-beyondmost.html#tab:sexcondmodel">2.8</a>.</p>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:sexcondmodel">Table 2.8: </span>Contributions to the likelihood function for the Sex Conditional Model for a sample of family compositions from the NLSY data
</caption>
<thead>
<tr>
<th style="text-align:left;">
Family composition
</th>
<th style="text-align:left;">
Likelihood contribution
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;width: 5cm; ">
G
</td>
<td style="text-align:left;width: 5cm; ">
<span class="math inline">\((1-p_{B|N})^{951}\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;width: 5cm; ">
GB
</td>
<td style="text-align:left;width: 5cm; ">
<span class="math inline">\((1-p_{B|N})^{666}p_{B|\textrm{G Bias}}^{666}\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;width: 5cm; ">
BGB
</td>
<td style="text-align:left;width: 5cm; ">
<span class="math inline">\(p_{B|N}^{2*148}(1-p_{B|\textrm{B Bias}})^{148}\)</span>
</td>
</tr>
</tbody>
</table>
<p>The products of the last three columns of Table <a href="ch-beyondmost.html#tab:table8chp2">2.9</a> provide the likelihood contributions for the Sex Conditional Model for all of the one-, two- and three-child NLSY families. We write the likelihood as a function of the three parameters <span class="math inline">\(p_{B|N}, p_{B|\textrm{B Bias}}\)</span>, and <span class="math inline">\(p_{B|\textrm{G Bias}}\)</span>.</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:table8chp2">Table 2.9: </span>Likelihood contributions for NLSY families in Sex Unconditional and Sex Conditional Models.
</caption>
<thead>
<tr>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="border-bottom:hidden" colspan="1">
</th>
<th style="border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="3">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Sex Conditional Model
</div>
</th>
</tr>
<tr>
<th style="text-align:left;">
Family composition
</th>
<th style="text-align:left;">
Num. families
</th>
<th style="text-align:left;">
Sex Unconditional
</th>
<th style="text-align:left;">
Child1
</th>
<th style="text-align:left;">
Child 2
</th>
<th style="text-align:left;">
Child 3
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
B
</td>
<td style="text-align:left;">
930
</td>
<td style="text-align:left;">
<span class="math inline">\(p_B\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(p_{B|N}\)</span>
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
G
</td>
<td style="text-align:left;">
951
</td>
<td style="text-align:left;">
<span class="math inline">\((1-p_B)\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(1-p_{B|N}\)</span>
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
BB
</td>
<td style="text-align:left;">
582
</td>
<td style="text-align:left;">
<span class="math inline">\(p_B^2\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(p_{B|N}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(p_{B|\textrm{B Bias}}\)</span>
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
BG
</td>
<td style="text-align:left;">
666
</td>
<td style="text-align:left;">
<span class="math inline">\(p_B (1-p_B)\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(p_{B|N}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(1-p_{B|\textrm{B Bias}}\)</span>
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
GB
</td>
<td style="text-align:left;">
666
</td>
<td style="text-align:left;">
<span class="math inline">\((1-p_B)p_B\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(1-p_{B|N}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(p_{B|\textrm{G Bias}}\)</span>
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
GG
</td>
<td style="text-align:left;">
530
</td>
<td style="text-align:left;">
<span class="math inline">\((1-p_B)^2\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(1-p_{B|N}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(1-p_{B|\textrm{G Bias}}\)</span>
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
BBB
</td>
<td style="text-align:left;">
186
</td>
<td style="text-align:left;">
<span class="math inline">\(p_B^3\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(p_{B|N}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(p_{B|\textrm{B Bias}}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(p_{B|\textrm{B Bias}}\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
BBG
</td>
<td style="text-align:left;">
177
</td>
<td style="text-align:left;">
<span class="math inline">\(p_B^2 (1-p_B)\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(p_{B|N}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(p_{B|\textrm{B Bias}}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(1-p_{B|\textrm{B Bias}}\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
BGG
</td>
<td style="text-align:left;">
173
</td>
<td style="text-align:left;">
<span class="math inline">\(p_B (1-p_B)^2\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(p_{B|N}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(1-p_{B|\textrm{B Bias}}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(1-p_{B|N}\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
BGB
</td>
<td style="text-align:left;">
148
</td>
<td style="text-align:left;">
<span class="math inline">\(p_B^2 (1-p_B)\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(p_{B|N}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(1-p_{B|\textrm{B Bias}}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(p_{B|N}\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
GBB
</td>
<td style="text-align:left;">
151
</td>
<td style="text-align:left;">
<span class="math inline">\(p_B^2 (1-p_B)\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(1-p_{B|N}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(p_{B|\textrm{G Bias}}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(p_{B|N}\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
GGB
</td>
<td style="text-align:left;">
125
</td>
<td style="text-align:left;">
<span class="math inline">\(p_B (1-p_B)^2\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(1-p_{B|N}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(1-p_{B|\textrm{G Bias}}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(p_{B|\textrm{G Bias}}\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
GBG
</td>
<td style="text-align:left;">
182
</td>
<td style="text-align:left;">
<span class="math inline">\(p_B(1-p_B)^2\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(1-p_{B|N}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(p_{B|\textrm{G Bias}}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(1-p_{B|N}\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
GGG
</td>
<td style="text-align:left;">
159
</td>
<td style="text-align:left;">
<span class="math inline">\((1-p_B)^3\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(1-p_{B|N}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(1-p_{B|\textrm{G Bias}}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(1-p_{B|\textrm{G Bias}}\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
log-likelihood
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
-7396.067
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
-7374.238
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
AIC
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
14794.13
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
14751.48
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
BIC
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
14810.68
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
14749.18
</td>
<td style="text-align:left;">
</td>
</tr>
</tbody>
</table>
<p><span class="math display">\[\begin{multline*}
 \mathrm{Lik}(p_{B|N},  p_{B|\textrm{B Bias}}, p_{B|\textrm{G Bias}}) \\
 = \big[ p_{B|N}^{930}(1-p_{B|N})^{951} ( p_{B|N}p_{B|\textrm{B Bias}})^{582} \cdots  \\
 ((1-p_{B|N})(1-p_{B|\textrm{G Bias}})(1-p_{B|\textrm{G Bias}}))^{159} \big] \\ 
 = \big[p_{B|N}^{3161}(1-p_{B|N})^{3119}p_{B|\textrm{B Bias}}^{1131} (1-p_{B|\textrm{B Bias}})^{1164}p_{B|\textrm{G Bias}}^{1124}(1-p_{B|\textrm{G Bias}})^{973} \big]
\end{multline*}\]</span></p>
<p><span class="math display" id="eq:log-likall">\[\begin{multline}
\log(\mathrm{Lik}(p_{B|N},  p_{B|\textrm{B Bias}}, p_{B|\textrm{G Bias}})) = \\  
 3161\log(p_{B|N})+3119\log(1-p_{B|N})+1131\log(p_{B|\textrm{B Bias}}) \\
 +1164\log(1-p_{B|\textrm{B Bias}})+1124\log(p_{B|\textrm{G Bias}})+ 973\log(1-p_{B|\textrm{G Bias}})
\tag{2.4} 
\end{multline}\]</span></p>
<p>To use calculus to estimate the probability of a boy entering a neutral family (a family with equal boys and girls), <span class="math inline">\(p_{B|N}\)</span>, we begin with the logarithm of the likelihood in equation <a href="ch-beyondmost.html#eq:log-likall">(2.4)</a>. Differentiating the log-likelihood with respect to <span class="math inline">\(p_{B|N}\)</span> holding all other parameters constant yields an intuitive estimate.</p>
<p><span class="math display">\[\begin{align*}
 \hat{p}_{B|N}&amp;=\frac{3161}{3161+3119} \\
 &amp;=0.5033
\end{align*}\]</span></p>
<p>There are 6,280 times when a child is joining a neutral family and, of those times, 3,161 are boys. Thus the MLE of the probability of a boy joining a family where the number of boys and girls are equal (including when there are no children) is 0.5033.</p>
<p>Similarly, MLEs for <span class="math inline">\(p_{B|\textrm{B Bias}}\)</span> and <span class="math inline">\(p_{B|\textrm{G Bias}}\)</span> can be obtained:</p>
<p><span class="math display">\[\begin{align*}
 \hat{p}_{B|\textrm{B Bias}}&amp;= \frac{1131}{1131+1164}\\
 &amp; =  0.4928 \\
 &amp;  \\
 \hat{p}_{B|\textrm{G Bias}}&amp;=\frac{1124}{1124+973}\\
&amp;= 0.5360
\end{align*}\]</span></p>
<p>Are these results consistent with the notion that boys or girls run in families? We consider the Sex Conditional Model because we hypothesized there would be a higher probability of boys among children born into families with a boy bias. However, we found that, if there is a boy bias, the probability of a subsequent boy was estimated to be actually less (0.493) than the probability of a subsequent girl. Similarly, girls join families with more girls than boys approximately 46.4% of the time so that there is little support for the idea that either “girls or boys run in families.”</p>
<p>Even though initial estimates don’t support the idea, let’s formally take a look as to whether prior gender composition affects the probability of a boy. To do so, we’ll see if the Sex Conditional Model is statistically significantly better than the Sex Unconditional Model.</p>
</div>
<div id="sec-lrtest" class="section level3">
<h3><span class="header-section-number">2.6.5</span> Comparing the Sex Unconditional to the Sex Conditional Model</h3>
<div id="nested-models" class="section level4">
<h4><span class="header-section-number">2.6.5.1</span> Nested Models</h4>
<p>Likelihoods are not only useful for fitting models, but they are also useful when comparing models. If the parameters for a reduced model are a subset of parameters for a larger model, we say the models are <strong>nested</strong>  and the difference between their likelihoods can be incorporated into a statistical test to help judge the benefit of including additional parameters. Another way in which to think of nesting is to consider whether parameters in the larger model can be equated to obtain the simpler model or whether some parameters in the larger model can be set to constants. Since <span class="math inline">\(p_{B|\textrm{B Bias}}, p_{B|N}\)</span> and <span class="math inline">\(p_{B|\textrm{G Bias}}\)</span> in the Sex Conditional Model can be set to <span class="math inline">\(p_B\)</span> to obtain the Sex Unconditional Model, we can say the models are nested.</p>
<p>If the parameters are not nested, comparing models with the likelihood can still be useful but will take a different form. We’ll see that the Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC) are functions of the log-likelihood that can be used to compare models even when the models are not nested. Either way we see that this notion of likelihood is pretty useful.</p>
<p><strong>Hypotheses</strong></p>
<p><span class="math inline">\(H_0: p_{B|N}=p_{B|\textrm{B Bias}}=p_{B|\textrm{G Bias}}=p_B\)</span> (Sex Unconditional Model)
The probability of a boy does not depend on the prior family composition.</p>
<p><span class="math inline">\(H_A:\)</span> At least one parameter from <span class="math inline">\(p_{B|N}, p_{B|\textrm{B Bias}},p_{B|\textrm{G Bias}}\)</span> differs from the others. (Sex Conditional Model)
The probability of a boy does depend on the prior family composition.</p>
<p>We start with the idea of comparing the likelihoods or, equivalently, the log-likelihoods of each model at their maxima. To do so, we use the log-likelihoods to determine the MLEs, and then replace the parameters in the log-likelihood with their MLEs, thereby finding the maximum value for the log-likelihood of each model. Here we will refer to the first model, the Sex Unconditional Model, as the <strong>reduced model</strong>,  noting that it has only a single parameter, <span class="math inline">\(p_B\)</span>. The more complex model, the Sex Conditional Model, has three parameters and is referred to here as the <strong>larger (full) model</strong>. We’ll use the MLEs derived earlier in Section <a href="ch-beyondmost.html#sex-cond-lik">2.6.4</a>.</p>
<p>The maximum of the log-likelihood for the reduced model can be found by replacing <span class="math inline">\(p_{B}\)</span> in the log-likelihood with the MLE of <span class="math inline">\(p_{B}\)</span>, 0.5075.</p>
<p><span class="math display">\[\begin{align*}
\log(\mathrm{Lik}(0.5075))&amp; = 5416\log(.5075) + 5256\log(1-.5075)\\
&amp;= -7396.067
\end{align*}\]</span></p>
<p>The maximum of the log-likelihood for the larger model can be found by replacing <span class="math inline">\(p_{B|N}, p_{B|\textrm{B Bias}}, p_{B|\textrm{G Bias}}\)</span> in the log-likelihood with 0.5033, 0.4928, and 0.5360, respectively.</p>
<p><span class="math display">\[\begin{align*}
 \log(\mathrm{Lik}(0.5033, 0.4928, 0.5360)) &amp;=  3161\log(.5033)+3119\log(1-.5033)\\
 &amp; {}+ 1131\log(.4928)+1164\log(1-.4928)\\
 &amp; {}+ 1124\log(.5360)+973\log(1-.5360)\\
 &amp;= -7391.448
\end{align*}\]</span></p>
<p>Take a look at the log-likelihoods—the maximum log-likelihood for the larger model is indeed larger (less negative). The maximum log-likelihood for the larger model is guaranteed to be at least as large as the maximum log-likelihood for the reduced model, so we’ll be interested in whether this observed difference in maximum log-likelihoods, -7391.448 -(-7396.067) = 4.619, is significant.</p>
<p>A result from statistical theory states that, when the reduced model is the true model, twice the difference of the maximum log-likelihoods follows a <span class="math inline">\(\chi^2\)</span> distribution with the degrees of freedom equal to the difference in the number of parameters between the two models. A difference of the maximum log-likelihoods can also be looked at as the log of the ratio of the likelihoods and for that reason the test is referred to as the <strong>Likelihood Ratio Test (LRT)</strong>. </p>
<p>Our test statistic is</p>
<p><span class="math display">\[\begin{equation*}
\begin{split}    
 \textrm{LRT} &amp;= 2[\max(\log(\mathrm{Lik}(\textrm{larger model}))) - \max(\log(\mathrm{Lik}(\textrm{reduced model})))] \\
     &amp;= 2\log\left(\frac{\max(\mathrm{Lik}(\textrm{larger  model}))}{\max(\mathrm{Lik}(\textrm{reduced model}))} \right)
\end{split}
\end{equation*}\]</span></p>
<p>Intuitively, when the likelihood for the larger model is much greater than it is for the reduced model, we have evidence that the larger model is more closely aligned with the observed data. This isn’t really a fair comparison on the face of it. We need to account for the fact that more parameters were estimated and used for the larger model. That is accomplished by taking into account the degrees of freedom for the <span class="math inline">\(\chi^2\)</span> distribution. The expected value of the <span class="math inline">\(\chi^2\)</span> distribution is its degrees of freedom. Thus when the difference in the number of parameters is large, the test statistic will need to be much larger to convince us that it is not simply chance variation with two identical models. Here, under the reduced model we’d expect our test statistic to be 2, when in fact it is over 9. The evidence favors our larger model. More precisely, the test statistic is <span class="math inline">\(2(-7391.448+7396.073) = 9.238\; (p=.0099)\)</span>, where the p-value is the probability of obtaining a value above 9.238 from a <span class="math inline">\(\chi^2\)</span> distribution with 2 degrees of freedom.</p>
<p>We have convincing evidence that the Sex Conditional Model provides a significant improvement over the Sex Unconditional Model. However, keep in mind that our point estimates for a probability of a boy were not what we had expected for “sex runs in families.” It may be that this discrepancy stems from behavioral aspects of family formation. The next section on stopping rules explores how types of couples’ decisions may affect the relative proportions of family compositions in the data.</p>
<p><em>Note: </em>You may notice that the LRT is similar in spirit to the extra-sum-of-squares F-test used in linear regression. Recall that the extra-sum-of-squares F-test involves comparing two nested models. When the smaller model is true, the F-ratio follows an F-distribution which on average is 1.0. A large, unusual F-ratio provides evidence that the larger model provides a significant improvement.</p>
<p><em>Also note: </em> It might have been more logical to start by using Likelihood Ratio Test to determine whether the probability of having a boy differs significantly from 0.5. We leave this as an exercise.</p>
</div>
</div>
</div>
<div id="model-3-stopping-rule-model-waiting-for-a-boy" class="section level2">
<h2><span class="header-section-number">2.7</span> Model 3: Stopping Rule Model (Waiting for a boy)</h2>
<p><span class="citation">Rodgers and Doughty (<a href="#ref-Rodgers2001" role="doc-biblioref">2001</a>)</span> offer one reason to explain the contradictory results: waiting for a male child. It has been noted by demographers that some parents are only interested in producing a male heir so that the appearance of a boy leads more often to the family ending childbearing. Stopping models investigate questions like: Are couples more likely to stop childbearing once they have a boy? Or are some parents waiting for a girl? Others might wish to have at least one boy and girl. The exploratory data analysis results in Table <a href="ch-beyondmost.html#tab:table7chp2">2.6</a> provide some insight but cannot definitively settle the question about couples’ stopping once they have a boy.</p>
<p>For stopping models, two probabilities are recorded for each child: the probability of the sex and the conditional probability of stopping after that child. As we have done in previous models, let <span class="math inline">\(p_B\)</span> = probability the child is a boy. When conditioning, every possible condition must have a probability associated with it. Here the stopping conditions for Model 3 are: stop on first boy <span class="math inline">\((S|B1)\)</span> or stopping on a child who is not the first boy <span class="math inline">\((S|N)\)</span>.</p>
<p><strong>Additional Parameters for the First Boy Stopping Model</strong></p>
<ul>
<li><span class="math inline">\(p_{S|B1}=\)</span> probability of stopping after the first boy</li>
<li><span class="math inline">\(1 - p_{S|B1}=\)</span> probability of not stopping after the first boy</li>
<li><span class="math inline">\(p_{S|N}=\)</span> probability of stopping after a child who is not the first boy</li>
<li><span class="math inline">\(1 - p_{S|N}=\)</span> probability of not stopping after a child who is not the first boy</li>
</ul>
<p>Our interest centers on whether the probability of stopping after the first boy, <span class="math inline">\(p_{S|B1}\)</span> is greater than stopping when it is not a first boy, <span class="math inline">\(p_{S|N}\)</span>.</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:table9chp2">Table 2.10: </span>Likelihood contributions for NLSY families in Model 3: Waiting for a boy.
</caption>
<thead>
<tr>
<th style="text-align:left;">
Family Composition
</th>
<th style="text-align:right;">
Num. families
</th>
<th style="text-align:left;">
Likelihood
</th>
<th style="text-align:left;">
Contribution
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;width: 3cm; ">
B
</td>
<td style="text-align:right;">
930
</td>
<td style="text-align:left;">
<span class="math inline">\(p_B\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(p_{S|B1}\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;width: 3cm; ">
G
</td>
<td style="text-align:right;">
951
</td>
<td style="text-align:left;">
<span class="math inline">\((1-p_B)\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(p_{S|N}\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;width: 3cm; ">
BB
</td>
<td style="text-align:right;">
582
</td>
<td style="text-align:left;">
<span class="math inline">\(p_B^2\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\((1-p_{S|B1}) p_{S|N}\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;width: 3cm; ">
BG
</td>
<td style="text-align:right;">
666
</td>
<td style="text-align:left;">
<span class="math inline">\(p_B (1-p_B)\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\((1-p_{S|B1}) p_{S|N}\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;width: 3cm; ">
GB
</td>
<td style="text-align:right;">
666
</td>
<td style="text-align:left;">
<span class="math inline">\((1-p_B)p_B\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\((1-p_{S|N}) p_{S|B1}\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;width: 3cm; ">
GG
</td>
<td style="text-align:right;">
530
</td>
<td style="text-align:left;">
<span class="math inline">\((1-p_B)^2\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\((1-p_{S|N})p_{S|N}\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;width: 3cm; ">
BBB
</td>
<td style="text-align:right;">
186
</td>
<td style="text-align:left;">
<span class="math inline">\(p_B^3\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\((1-p_{S|B1}) (1-p_{S|N})p_{S|N}\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;width: 3cm; ">
BBG
</td>
<td style="text-align:right;">
177
</td>
<td style="text-align:left;">
<span class="math inline">\(p_B^2 (1-p_B)\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\((1-p_{S|B1}) (1-p_{S|N})p_{S|N}\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;width: 3cm; ">
BGG
</td>
<td style="text-align:right;">
173
</td>
<td style="text-align:left;">
<span class="math inline">\(p_B (1-p_B)^2\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\((1-p_{S|B1}) (1-p_{S|N})p_{S|N}\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;width: 3cm; ">
BGB
</td>
<td style="text-align:right;">
148
</td>
<td style="text-align:left;">
<span class="math inline">\(p_B^2 (1-p_B)\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\((1-p_{S|B1}) (1-p_{S|N})p_{S|N}\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;width: 3cm; ">
GBB
</td>
<td style="text-align:right;">
151
</td>
<td style="text-align:left;">
<span class="math inline">\(p_B^2 (1-p_B)\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\((1-p_{S|N}) (1-p_{S|B1})p_{S|N}\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;width: 3cm; ">
GGB
</td>
<td style="text-align:right;">
125
</td>
<td style="text-align:left;">
<span class="math inline">\(p_B (1-p_B)^2\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\((1-p_{S|N})^2 p_{S|B1}\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;width: 3cm; ">
GBG
</td>
<td style="text-align:right;">
182
</td>
<td style="text-align:left;">
<span class="math inline">\(p_B(1-p_B)^2\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\((1-p_{S|N}) (1-p_{S|B1})p_{S|N}\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;width: 3cm; ">
GGG
</td>
<td style="text-align:right;">
159
</td>
<td style="text-align:left;">
<span class="math inline">\((1-p_B)^3\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\((1-p_{S|N})^2 p_{S|N}\)</span>
</td>
</tr>
</tbody>
</table>
<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:table10chp2">Table 2.11: </span>Patterns related to stopping decisions.
</caption>
<thead>
<tr>
<th style="text-align:left;">
Child is…
</th>
<th style="text-align:left;">
total children
</th>
<th style="text-align:left;">
prop of all children
</th>
<th style="text-align:left;">
n.stops (n.families)
</th>
<th style="text-align:left;">
prop stopped after these children
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;width: 3cm; ">
a boy who is the only boy in the family up to that point
</td>
<td style="text-align:left;width: 3cm; ">
3,986
</td>
<td style="text-align:left;width: 3cm; ">
37.4%
</td>
<td style="text-align:left;width: 3cm; ">
1,721
</td>
<td style="text-align:left;width: 3cm; ">
43.2%
</td>
</tr>
<tr>
<td style="text-align:left;width: 3cm; ">
not an only boy in the family up to that point
</td>
<td style="text-align:left;width: 3cm; ">
6,686
</td>
<td style="text-align:left;width: 3cm; ">
62.2%
</td>
<td style="text-align:left;width: 3cm; ">
3,905
</td>
<td style="text-align:left;width: 3cm; ">
58.4%
</td>
</tr>
<tr>
<td style="text-align:left;width: 3cm; ">
a girl who is the only girl in the family up to that point
</td>
<td style="text-align:left;width: 3cm; ">
3,928
</td>
<td style="text-align:left;width: 3cm; ">
36.8%
</td>
<td style="text-align:left;width: 3cm; ">
1,794
</td>
<td style="text-align:left;width: 3cm; ">
45.7%
</td>
</tr>
<tr>
<td style="text-align:left;width: 3cm; ">
not an only girl in the family up to that point
</td>
<td style="text-align:left;width: 3cm; ">
3,832
</td>
<td style="text-align:left;width: 3cm; ">
63.2%
</td>
<td style="text-align:left;width: 3cm; ">
3,832
</td>
<td style="text-align:left;width: 3cm; ">
56.8%
</td>
</tr>
<tr>
<td style="text-align:left;width: 3cm; ">
</td>
<td style="text-align:left;width: 3cm; ">
10,672
</td>
<td style="text-align:left;width: 3cm; ">
</td>
<td style="text-align:left;width: 3cm; ">
5,626
</td>
<td style="text-align:left;width: 3cm; ">
</td>
</tr>
</tbody>
</table>
<p>Using calculus, the MLEs are derived to be <span class="math inline">\(\hat{p}_B = 0.507\)</span>, <span class="math inline">\(\hat{p}_{S|B1} = 0.432\)</span>, and <span class="math inline">\(\hat{p}_{S|N} = 0.584\)</span>. These are consistent with intuition. The estimated proportion of boys for this model is the same as the estimate for the Sex Unconditional Model (Model 1). The estimates of the stopping parameters are consistent with the fact that of the 3,986 first boys, parents stop 43.2% of the time and of the 6,686 children who are not first boys childbearing stopped 58.4% of the time. See Table <a href="ch-beyondmost.html#tab:table10chp2">2.11</a></p>
<p>These results do, in fact, suggest that the probability a couple stops childbearing on the first boy is different than the probability of stopping at a child who is not the first boy, but the direction of the difference does not imply that couples “wait for a boy;” rather it appears that they are less likely to stop childbearing after the first boy in comparison to children who are not the first born male.</p>
<p>Similarly, for girls, the MLEs are <span class="math inline">\(\hat{p}_{S|G1}\)</span> = 0.457 and <span class="math inline">\(\hat{p}_{S|N}\)</span> = 0.568. Once again, the estimates do not provide evidence of waiting for a girl.</p>
<div id="non-nested-models" class="section level3">
<h3><span class="header-section-number">2.7.1</span> Non-nested Models</h3>
<p>How does the waiting for a boy model compare to the waiting for a girl model? Thus far we’ve seen how nested models can be compared. But these two models are not nested since one is not simply a reduced version of the other. Two measures referred to as information criteria, AIC and BIC, are useful when comparing non-nested models. Each measure can be calculated for a model using a function of the model’s maximum log-likelihood. You can find the log-likelihood in the output from most modeling software packages.</p>
<ul>
<li><span class="math inline">\(\textrm{AIC} = -2 (\textrm{maximum log-likelihood }) + 2p\)</span>, where <span class="math inline">\(p\)</span> represents the number of parameters in the fitted model. AIC stands for Akaike Information Criterion.  Because smaller AICs imply better models, we can think of the second term as a penalty for model complexity—the more variables we use, the larger the AIC.</li>
<li><span class="math inline">\(\textrm{BIC} = -2 (\textrm{maximum log-likelihood }) + p\log(n)\)</span>, where <span class="math inline">\(p\)</span> is the number of parameters and <span class="math inline">\(n\)</span> is the number of observations. BIC stands for Bayesian Information Criterion,  also known as Schwarz’s Bayesian criterion (SBC). Here we see that the penalty for the BIC differs from the AIC, where the log of the number of observations places a greater penalty on each extra predictor, especially for large datasets.</li>
</ul>
<p>So which explanation of the data seems more plausible—waiting for a boy or waiting for a girl? These models are not nested (i.e., one is not a simplified version of the other), so it is not correct to perform a Likelihood Ratio Test, but we can legitimately compare these models using information criteria (Table <a href="ch-beyondmost.html#tab:tab1chp2">2.12</a>).</p>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:tab1chp2">Table 2.12: </span>Measures of model performance with NLSY data: Waiting for a Boy vs. Waiting for a Girl Model.
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Waiting for a boy
</th>
<th style="text-align:right;">
Waiting for a girl
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
max log-likelihood
</td>
<td style="text-align:right;">
-14661
</td>
<td style="text-align:right;">
-14716
</td>
</tr>
<tr>
<td style="text-align:left;">
AIC
</td>
<td style="text-align:right;">
29324
</td>
<td style="text-align:right;">
29433
</td>
</tr>
<tr>
<td style="text-align:left;">
BIC
</td>
<td style="text-align:right;">
29332
</td>
<td style="text-align:right;">
29441
</td>
</tr>
</tbody>
</table>
<p>Smaller AIC and BIC are preferred, so here the Waiting for a Boy Model is judged superior to the Waiting for a Girl Model, suggesting that couples waiting for a boy is a better explanation of the data than waiting for a girl. However, for either boys and girls, couples do not stop more frequently after the first occurrence.</p>
<p>Other stopping rule models are possible. Another model could be that couples wait to stop until they have both a boy and a girl. We leave the consideration of this balance-preference model as an exercise.</p>
</div>
</div>
<div id="summary-of-model-building" class="section level2">
<h2><span class="header-section-number">2.8</span> Summary of Model Building</h2>
<p>Using a Likelihood Ratio Test, we found statistical evidence that the Sex Conditional Model (Sex Bias) is preferred to the Sex Unconditional Models. However, the parameter estimates were not what we expected if we believe that sex runs in families. Quite to the contrary, the results suggested that if there were more of one sex in a family, the next child is likely to be of the other sex. The results may support the idea that gender composition tends to “even out” over time.</p>
<p>Using AICs and BICs to compare the non-nested models of waiting for a boy or waiting for a girl, we found that the model specifying stopping for a first boy was superior to the model for stopping for the first girl. Again, neither model suggested that couples were <em>more</em> likely to stop after the first male or female, rather it appeared just the opposite—couples were <em>less</em> likely to be stopping after the first boy or first girl.</p>
<p>These results may need to be considered conditional on the size of a family. In which case, a look at the exploratory data analysis results may be informative. The reported percentages in Table <a href="ch-beyondmost.html#tab:table6chp2">2.5</a> could be compared to the percentages expected if the sex of the baby occurs randomly, P(all one sex|2 child family) = 1/2, and we observed 45%. For three child families, P(all one sex|3 child family) = 1/4, and we observed 27%. There is very slight evidence for sex running in families for three child families and none for two child families.</p>
<p>Under a random model that assumes the probability of a boy is 50%, the percentage of one-, two- and three- child families with the the first boy showing up last in the family is 50%, 25%, and 12.5%, respectively. Comparing these probabilities to what was observed in the data in Table <a href="ch-beyondmost.html#tab:table7chp2">2.6</a>, we find little support for the idea that couples are waiting for a boy.</p>
<p>We can perform a LRT to compare stopping at the first boy to a Random Stopping Model. The parameters for the first model (waiting for a boy) are <span class="math inline">\(p_B, p_{S|B1}, p_{S|N}\)</span> and the parameters for the second model (random stopping) are <span class="math inline">\(p_B\)</span> and <span class="math inline">\(p_S\)</span>. The results suggest that the Waiting for a Boy Model is significantly better than the Random Stopping Model. The Random Stopping Model takes into account that the odds of stopping after a child are not 50-50, but may be closer to the MLE for <span class="math inline">\(p_S\)</span> of 52.7%. We leave the derivation of this result as an exercise.</p>
</div>
<div id="likelihood-based-methods" class="section level2">
<h2><span class="header-section-number">2.9</span> Likelihood-based Methods</h2>
<p>With likelihood methods, we are no longer restricted to independent, identically distributed normal responses (iidN). Likelihood methods can accommodate non-normal responses and correlated data. Likelihood-based methods are useful for every model in this text, so that it is worth your time and effort to understand them.</p>
<p>Models that in the past you would fit using ordinary least squares can also be fit using the principle of maximum likelihood. It is pleasing to discover that under the right assumptions the maximum likelihood estimates (MLEs) for the intercept and slope in a linear regression are identical to ordinary least squares estimators (OLS) despite the fact that they are obtained in quite different ways.</p>
<p>Beyond the intuitively appealing aspects of MLEs, they also have some very desirable statistical properties. You learn more about these features in a statistical theory course. Here we briefly summarize the highlights in non-technical terms. MLEs are <em>consistent</em>; i.e., MLEs converge in probability to the true value of the parameter as the sample size increases. MLEs are <em>asymptotically normal</em>; as the sample size increases, the distribution of MLEs is closer to normal. MLEs are <em>efficient</em> because no consistent estimator has a lower mean squared error. Of all the estimators that produce unbiased estimates of the true parameter value, no estimator will have a smaller mean square error than the MLE. While likelihoods are powerful and flexible, there are times when likelihood-based methods fail: either MLEs do not exist, likelihoods cannot be written down, or MLEs cannot be written explicitly. It is also worth noting that other approaches to the likelihood, such as bootstrapping, can be employed.</p>
</div>
<div id="likelihoods-and-this-course" class="section level2">
<h2><span class="header-section-number">2.10</span> Likelihoods and this Course</h2>
<p><span class="citation">Rodgers and Doughty (<a href="#ref-Rodgers2001" role="doc-biblioref">2001</a>)</span> noted that</p>
<blockquote>
<p>Many factors have been identified that can potentially affect the human sex
ratio at birth. A 1972 paper by Michael Teitelbaum accounted for around 30
such influences, including drinking water, coital rates, parental age, parental
socioeconomic status, birth order, and even some societal-level influences like
wars and environmental pathogens.</p>
</blockquote>
<p>This chapter on likelihood ignored these complicating factors and was intentionally kept simple to impress you with the fact that likelihoods are conceptually straightforward. Likelihoods answer the sensible question of how likely you are to see your data in different settings. When the likelihood is simple as in this chapter, you can roughly determine an MLE by looking at a graph or you can be a little more precise by using calculus or, most conveniently, software. As we progress throughout the course, the likelihoods will become more complex and numerical methods may be required to obtain MLEs, yet the concept of an MLE will remain the same. Likelihoods will show up in parameter estimation, model performance assessment, and model comparisons.</p>
<p>One of the reasons many of the likelihoods will become complex is because of covariates. Here we estimated probabilities of having a boy in different settings, but we did not use any specific information about families other than sex composition. The problems in the remainder of the book will typically employ covariates. For example, suppose we had information on paternal age for each family. Consider the Sex Unconditional Model, and let</p>
<p><span class="math display">\[
p_B= \frac{e^{\beta_0+\beta_1(\textrm{parental age})}}
{1+e^{\beta_0+\beta_1(\textrm{parental age})}}
\]</span>.</p>
<p>(We will give a good reason for this crazy-looking expression for <span class="math inline">\(p_B\)</span> in later chapters.) The next step would be to replace <span class="math inline">\(p_B\)</span> in the likelihood, <span class="math inline">\(\mathrm{Lik}(p_B)\)</span>, (Equation <a href="ch-beyondmost.html#eq:lik30">(2.1)</a>), with the complicated expression for <span class="math inline">\(p_B\)</span>. The result would be a function of <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>. We could then use calculus to find the MLEs for <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>.</p>
<p>Another compelling reason for likelihoods occurs when we encounter correlated data. For example, models with conditional probabilities do not conform to the independence assumption. The Sex Conditional Model is an example of such a model. We’ll see that likelihoods can be useful when the data has structure such as multilevel that induces a correlation. A good portion of the book addresses this.</p>
<p>When the responses are are not normal such as in generalized linear models, where we see binary responses and responses which are counts, we’ll find it difficult to use the linear least squares regression models of the past and we’ll find the flexibility of likelihood methods to be extremely useful. Likelihood methods will enable us to move <em>beyond multiple linear regression</em>!</p>
</div>
<div id="exercises-1" class="section level2">
<h2><span class="header-section-number">2.11</span> Exercises</h2>
<div id="conceptual-exercises-1" class="section level3">
<h3><span class="header-section-number">2.11.1</span> Conceptual Exercises</h3>
<ol style="list-style-type: decimal">
<li>Suppose we plan to use data to estimate one parameter, <span class="math inline">\(p_B\)</span>.
<ul>
<li>When using a likelihood to obtain an estimate for the parameter, which is preferred: a large or a small likelihood value? Why?</li>
<li>The height of a likelihood curve is the probability of the data for the given parameter. The horizontal axis represents different
possible parameter values. Does the area under the likelihood curve for an interval from .25 to .75 equal the probability that the
true probability of a boy is between 0.25 and 0.75?</li>
</ul></li>
<li>Suppose the families with an “only child” were excluded for the Sex Conditional Model. How might the estimates for the three parameters be affected? Would it still be possible to perform a Likelihood Ratio Test to compare the Sex Unconditional and Sex Conditional Models? Why or why not?</li>
<li>Come up with an alternative model to investigate whether “sex runs in families.”</li>
</ol>
</div>
<div id="guided-exercises-1" class="section level3">
<h3><span class="header-section-number">2.11.2</span> Guided Exercises</h3>
<ol style="list-style-type: decimal">
<li>Write out the likelihood for a model which assumes the probability of a girl equals the probability of a boy. Carry out a LRT to determine whether there is evidence that the two probabilities are not equal. Comment on the practical significance of this finding (there is not necessarily one correct answer).</li>
<li><strong>Case 3</strong> In Case 1 we used hypothetical data with 30 boys and 20 girls. Case 2 was a much larger study with 600 boys and 400 girls. Consider Case 3, a hypothetical data set with 6000 boys and 4000 girls.
<ul>
<li>Use the methods for Case 1 and Case 2 and determine the MLE for <span class="math inline">\(p_B\)</span> for the independence model. Compare your result to the MLEs for Cases 1 and 2.</li>
<li>Describe how the graph of the log-likelihood for Case 3 would compare to the log-likelihood graphs for Cases 1 and 2.</li>
<li>Compute the log-likelihood for Case 3. Why is it incorrect to perform an LRT comparing Cases 1, 2, and 3?</li>
</ul></li>
<li>Write out an expression for the likelihood of seeing our NLSY data (5,416 boys and 5,256 girls) if the true probability of a boy is:
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(p_B=0.5\)</span><br />
</li>
<li><span class="math inline">\(p_B=0.45\)</span><br />
</li>
<li><span class="math inline">\(p_B= 0.55\)</span><br />
</li>
<li><span class="math inline">\(p_B= 0.5075\)</span><br />
</li>
</ol>
<ul>
<li>Compute the value of the log-likelihood for each of the values of <span class="math inline">\(p_B\)</span> above.</li>
<li>Which of these four possibilities, <span class="math inline">\(p_B=0.45, p_B=0.5, p_B=0.55,\)</span> or <span class="math inline">\(p_B=0.5075\)</span> would be the best estimate
of <span class="math inline">\(p_B\)</span> given what we observed (our data)?</li>
</ul></li>
<li>Compare the Waiting for a Boy Model to a Random Stopping Model. The parameters for the first model (Waiting for a Boy) are <span class="math inline">\(p_B\)</span>, <span class="math inline">\(p_{S|B1}\)</span>, <span class="math inline">\(p_{S|N}\)</span> and the parameters for the second model (Random Stopping) are <span class="math inline">\(p_B\)</span> and <span class="math inline">\(p_S\)</span>. Use an intuitive approach to arrive at the MLEs for the parameters for each model. Perform a LRT to compare these two models.</li>
</ol>
</div>
<div id="open-ended-exercise" class="section level3">
<h3><span class="header-section-number">2.11.3</span> Open-ended Exercise</h3>
<ol style="list-style-type: decimal">
<li><p><strong>Another Stopping Rule Model: Balance-preference</strong>
Can you construct a model which suggests that childbearing is stopped when couples have a boy <em>and</em> a girl? Define the parameter(s) for balance-preference stopping combined with the sex conditional model and write out likelihood contributions for the same family compositions that appear in Table <a href="ch-beyondmost.html#tab:table3chp2">2.3</a>.</p>
<ul>
<li><strong>Extra Credit</strong> Obtain the MLEs for your balance-preference model parameters and interpret the results. Then, compare the balance-preference stopping rule model to the random stopping model using a LRT.</li>
</ul></li>
<li><p><strong>The Hot Hand in Basketball</strong> <span class="citation">Gilovich, Vallone, and Tversky (<a href="#ref-Gilovich1985" role="doc-biblioref">1985</a>)</span> wrote a controversial but compelling article claiming that there is no such thing as “the hot hand” in basketball. That is, there is no empirical evidence that shooters have stretches where they are more likely to make consecutive shots, and basketball shots are essentially independent events. One of the many ways they tested for evidence of a “hot hand” was to record sequences of shots for players under game conditions and determine if players are more likely to make shots after made baskets than after misses. For instance, assume we recorded data from one player’s first 5 three-point attempts over a 5-game period. We can assume games are independent, but we’ll consider two models for shots within a game:</p>
<ul>
<li><p>No Hot Hand (1 parameter): <span class="math inline">\(p_B\)</span> = probability of making a basket (thus <span class="math inline">\(1-p_B\)</span> = probability of not making a basket)</p></li>
<li><p>Hot Hand (2 parameters): <span class="math inline">\(p_B\)</span> = probability of making a basket after a miss (or the first shot of a game); <span class="math inline">\(p_{B|B}\)</span> = probability of making a basket after making the previous shot</p></li>
</ul>
<ol style="list-style-type: lower-alpha">
<li><p>Fill out Table <a href="ch-beyondmost.html#tab:hothandchp2">2.13</a>—write out the contribution of each game to the likelihood for both models along with the total likelihood for each model.</p></li>
<li><p>Given that, for the No Hot Hand model, <span class="math inline">\(\textrm{Lik}(p_B)=p_B^{10}(1-p_B)^{15}\)</span> for the 5 games where we collected data, how do we know that 0.40 (the maximum likelihood estimator (MLE) of <span class="math inline">\(p_B\)</span>) is a better estimate than, say, 0.30?</p></li>
<li><p>Find the MLEs for the parameters in each model, and then use those MLEs to determine if there’s significant evidence that the hot hand exists.</p></li>
</ol></li>
</ol>
<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:hothandchp2">Table 2.13: </span>Data for Open Exercise 2. B = made basket. M = missed basket.
</caption>
<thead>
<tr>
<th style="text-align:left;">
Game
</th>
<th style="text-align:left;">
First 5 shots
</th>
<th style="text-align:left;">
Likelihood (No Hot Hand)
</th>
<th style="text-align:left;">
Likelihood (Hot Hand)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;width: 2cm; ">
1
</td>
<td style="text-align:left;width: 2cm; ">
BMMBB
</td>
<td style="text-align:left;width: 2cm; ">
</td>
<td style="text-align:left;width: 2cm; ">
</td>
</tr>
<tr>
<td style="text-align:left;width: 2cm; ">
2
</td>
<td style="text-align:left;width: 2cm; ">
MBMBM
</td>
<td style="text-align:left;width: 2cm; ">
</td>
<td style="text-align:left;width: 2cm; ">
</td>
</tr>
<tr>
<td style="text-align:left;width: 2cm; ">
3
</td>
<td style="text-align:left;width: 2cm; ">
MMBBB
</td>
<td style="text-align:left;width: 2cm; ">
</td>
<td style="text-align:left;width: 2cm; ">
</td>
</tr>
<tr>
<td style="text-align:left;width: 2cm; ">
4
</td>
<td style="text-align:left;width: 2cm; ">
BMMMB
</td>
<td style="text-align:left;width: 2cm; ">
</td>
<td style="text-align:left;width: 2cm; ">
</td>
</tr>
<tr>
<td style="text-align:left;width: 2cm; ">
5
</td>
<td style="text-align:left;width: 2cm; ">
MMMMM
</td>
<td style="text-align:left;width: 2cm; ">
</td>
<td style="text-align:left;width: 2cm; ">
</td>
</tr>
<tr>
<td style="text-align:left;width: 2cm; ">
Total
</td>
<td style="text-align:left;width: 2cm; ">
</td>
<td style="text-align:left;width: 2cm; ">
</td>
<td style="text-align:left;width: 2cm; ">
</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-BBCNEWS1995">
<p>BBC News. 2009. “Sisters ‘Make People Happy’.” <a href="http://news.bbc.co.uk/2/hi/health/7977454.stm">http://news.bbc.co.uk/2/hi/health/7977454.stm</a>.</p>
</div>
<div id="ref-NLSY1997">
<p>Bureau of Labor Statistics. 1997. “National Longitudinal Surveys.” <a href="https://www.bls.gov/nls/nlsy97.htm">https://www.bls.gov/nls/nlsy97.htm</a>.</p>
</div>
<div id="ref-CIA2013">
<p>Central Intelligence Agency. 2013. “The World Factbook 2013.” <a href="https://www.cia.gov/library/publications/download/download-2013/index.html">https://www.cia.gov/library/publications/download/download-2013/index.html</a>.</p>
</div>
<div id="ref-Gilovich1985">
<p>Gilovich, Thomas, Robert Vallone, and Amos Tversky. 1985. “The Hot Hand in Basketball: On the Misperception of Random Sequences.” <em>Cognitive Psychology</em> 17 (3): 295–314. <a href="https://doi.org/10.1016/0010-0285(85)90010-6">https://doi.org/10.1016/0010-0285(85)90010-6</a>.</p>
</div>
<div id="ref-Komdeur1997">
<p>Komdeur, Jan, Serge Daan, Joost Tinbergen, and Christa Mateman. 1997. “Extreme Adaptive Modification in Sex Ratio of the Seychelles Warbler’s Eggs.” <em>Nature</em> 385 (February): 522–25. <a href="http://dx.doi.org/10.1038/385522a0">http://dx.doi.org/10.1038/385522a0</a>.</p>
</div>
<div id="ref-Mathews2005">
<p>Mathews, T. J., and Brady E. Hamilton. 2005. “Trend Analysis of the Sex Ratio at Birth in the United States.” <em>National Vital Statistics Reports</em> 53 (20): 1–20. <a href="https://www.cdc.gov/nchs/data/nvsr/nvsr53/nvsr53_20.pdf">https://www.cdc.gov/nchs/data/nvsr/nvsr53/nvsr53_20.pdf</a>.</p>
</div>
<div id="ref-Rodgers2001">
<p>Rodgers, Joseph Lee, and Debby Doughty. 2001. “Does Having Boys or Girls Run in the Family?” <em>CHANCE</em> 14 (4): 8–13. <a href="http://dx.doi.org/10.1080/09332480.2001.10542293">http://dx.doi.org/10.1080/09332480.2001.10542293</a>.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>Note: A nice property of MLEs is demonstrated here. We have the MLE for <span class="math inline">\(p_{B|\textrm{G Bias}}\)</span>, and we want the MLE of <span class="math inline">\(p_{G|\textrm{G Bias}}=1-p_{B|\textrm{G Bias}}\)</span>. We can get it by replacing <span class="math inline">\(p_{B|\textrm{G Bias}}\)</span> with its MLE; i.e., <span class="math inline">\(\hat{p}_{G|\textrm{G Bias}}=1-\hat{p}_{B|\textrm{G Bias}}\)</span>. In mathematical terms, you can get the MLE of a function by applying the function to the original MLE.<a href="ch-beyondmost.html#fnref1" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="ch-MLRreview.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="ch-distthry.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/lunr.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-BeyondMLR.pdf"],
"toc": {
"collapse": "subsection",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
